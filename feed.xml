<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://conor-hamill.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://conor-hamill.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-07-23T20:37:41+00:00</updated><id>https://conor-hamill.github.io/feed.xml</id><title type="html">Conor B. Hamill</title><subtitle>Personal website for Conor Hamill. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">The Geometry of Money: How we used Graph Neural Networks to transform financial network analysis</title><link href="https://conor-hamill.github.io/blog/2025/the-geometry-of-money-how-we-used-graph-neural-networks-to-transform-financial-network-analysis/" rel="alternate" type="text/html" title="The Geometry of Money: How we used Graph Neural Networks to transform financial network analysis"/><published>2025-06-23T13:30:48+00:00</published><updated>2025-06-23T13:30:48+00:00</updated><id>https://conor-hamill.github.io/blog/2025/the-geometry-of-money-how-we-used-graph-neural-networks-to-transform-financial-network-analysis</id><content type="html" xml:base="https://conor-hamill.github.io/blog/2025/the-geometry-of-money-how-we-used-graph-neural-networks-to-transform-financial-network-analysis/"><![CDATA[<p>By <a href="https://www.linkedin.com/in/wu-yiming/">Yiming Wu (Senior Data Scientist, Applied AI)</a> and<br/><a href="https://www.linkedin.com/in/mihirtare/">Mihir Tare (Data Scientist, Applied AI)</a></p> <h3>Introduction</h3> <p>Large financial organisations process millions of transactions every day and each one tells a small story — who paid whom, when and how much. Analysing these interactions helps us uncover patterns across customer habits, business trends, signs of fraud and so on. In this blog, we will showcase how we used a unique network-based approach to unlock the potential of transactional data in the context of banking.</p> <h3>From Tables to Tangled Webs</h3> <p>Traditional analytical methods often struggle to effectively leverage the information contained within these interactions. Using a classic tabular approach overlooks a key strength of this data as it fails to capture how people and businesses are connected. Here, transaction data is normally represented in a tabular format where each row represents a single transaction, containing attributes like sender, receiver, amount, time etc. Each transaction is treated as an independent event, which is efficient for storage and querying of the data, but fails to capture any relational structure within it. Traditional machine learning models rely on these structured datasets and struggle to leverage the connections between the rows.</p> <p>We take a different approach to address this problem by utilising mathematical objects, called <em>graphs</em>, to analyse transaction networks. A graph is a mathematical structure used to represent information in the form of nodes and edges. Nodes are used to represent entities, like accounts or merchants, and edges are used to represent the connections between these nodes, like monetary transactions. In the world of financial analytics, the terms graphs and networks are often used interchangeably. By shifting from tabular to graphical representations, we can apply graph-based machine learning techniques that are better suited to uncovering hidden structures, community behaviour, and anomalies in transaction data.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/690/0*MvEVL4MnZd9y6LtT.png"/><figcaption><em>Left: Each row shows a single transaction with a sender, receiver, and amount. While this format is easy to store and query, it does not reveal how entities are connected across multiple transactions.</em><br/><em>Right: The same data visualised as a network. Nodes represent people, and edges represent transactions. This structure makes it easier to detect patterns, such as loops or clusters, in the flow of money.</em></figcaption></figure> <h3>NatWest Transactions on a Graph</h3> <p>Following the simple example above, we designed our population to construct a well-rounded graphical representation of all the interactions between the accounts on our transaction data.</p> <p>The transaction network contains four types of nodes:</p> <ol><li><strong>Core account</strong>: current accounts with core brands in NatWest retail banking that are based in the UK.</li><li><strong>Non-core account</strong>: a UK-based account that is not a core account and has sent or received a transaction from a core domestic account. This could be any external UK account or non-core internal account in NatWest.</li><li><strong>Foreign account</strong>: a non-UK based account (international accounts).</li><li><strong>Merchant</strong>: any merchant that has received a point of sales (POS) payment or issued a refund to a core account.</li></ol> <p>These 4 node types induce 7 types of edges on the graph which can be seen in the figure below. While the edge types are described individually, they all indicate the same underlying interaction on the network — a flow of money between two accounts — and are uniquely identifiable using the sender-receiver account types pair.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/517/0*F618e8gnYo-oTozg.jpeg"/><figcaption>The typological structure of our graph</figcaption></figure> <p>The resulting graph contained over 100 million transaction and over 10 million nodes.</p> <h3>Lost in the Graph? Let Embeddings Guide You</h3> <p>Great, so now you have an intuitive way to visualise your transaction data on a graph, but how do we use this? This is one of the main challenges when it comes to using graph-based approaches in the world of machine learning. As most models use fixed-length tabular data as inputs, not graphs, we turn towards a special suite of models called Graph Neural Networks (GNNs). Using a GNN, we can do one of two things:</p> <ul><li>Train the model to predict outcomes for a certain task, like fraud detection</li><li>Train a representation learning model that can translate the information on a graph into fixed-length vectors called <em>embeddings</em>.</li></ul> <p>While the first is a viable option, the model is purpose built and commits to solving only one task using only the graph information. On the other hand, embeddings are a general-purpose, reusable asset containing summarised information about interactions on the graph. This allows us to use graph information in solving various problems, without any additional processing, alongside other useful data.</p> <h3>Scalable Representation Learning with GraphSAGE</h3> <p>As noted earlier, large banks process millions of transactions every day. In order to train an embedding model for this massive network, your algorithm must be able to scale efficiently. We achieve this by adopting a sampling-based embedding algorithm known as GraphSAGE. GraphSAGE avoids processing the entire graph at once by sampling a small set of neighbouring nodes for each node during training. The sampled neighbourhood is passed to an information aggregator to compute embeddings for each node. This makes it possible to train on massive graphs without running into memory or time constraints.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/800/0*gqe1y4tVgRCGsd4B.gif"/><figcaption><em>Animation: the GraphSAGE training process; source:</em> [1]</figcaption></figure> <p>In our implementation, we use a mean aggregator for computing the embeddings and sample neighbouring nodes uniformly at random. In addition to maintaining computational efficiency, the neighbourhood sampler also nullifies the impact of <em>super-connected</em> nodes, such as supermarkets with thousands of daily transactions, on the training duration.</p> <p>As with training traditional neural networks, we had to use a loss function to optimise the trainable parameters of the model. Taking inspiration directly from the original publication of GraphSAGE [2], we implemented an unsupervised loss function which maximises the similarity in the embeddings of neighbouring nodes and minimises the similarity in the embeddings of non-neighbouring nodes. Here, the neighbouring nodes are obtained through the neighbourhood sampling stage and the non-neighbouring nodes are obtained using a negative sampling distribution. The negative samples are examples of nodes that are not connected on the graph and allow the model to learn what dissimilar accounts look like. This is done uniformly at random by sampling edges that do not exist on the transaction network. This part of the implementation is key for enabling the embeddings to be a reusable asset.</p> <p>This three-stage algorithm enables the model parameters to be trained in mini-batches on GPU-enabled machines by using standard stochastic gradient descent and backpropagation. The model was trained on a graph containing over 100 million transactions using g5.16xlarge AWS EC2 instance in 4 hours and was able to run inference on a g5.8xlarge instance in under 20 minutes. The output embeddings from the model are 32-dimensional vectors and the hyperparameters were optimised based on empirical experiments that balanced model complexity and performance.</p> <h3>Do These Numbers Mean Anything?</h3> <p>We trained our GraphSAGE model to compute 32-dimensional embeddings for all the accounts and merchants in our transaction network.These embeddings are compact numerical representations that capture the structure and behavior of each account based on its transactions on the network. At first glance, these embeddings are abstract pieces of information; vectors of numbers that don’t inherently “mean” anything in isolation. However, their power lies in how they relate to one another. Accounts that are structurally or behaviourally similar on the network will have embeddings that are close together in this high-dimensional embedding space.</p> <p>To validate this claim, we computed the cosine similarity between embeddings of connected nodes (i.e. accounts that have transacted with each other) and compared them to disconnected nodes. The results showed a clear pattern: connected nodes had higher similarity scores on average, indicating that the embeddings successfully captured meaningful relationships from the transaction graph. This cosine similarity difference was an interpretable measure of how the unsupervised model was performing at its task. As a result, we used it as a lightweight metric to monitor the model performance in production, enabling us detect issues like model degradation.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/640/0*rYJdxxXCMvSeykG2.png"/><figcaption><em>Average cosine similarity between the embeddings of neighbouring and non-neighbouring nodes across 10 weeks. The shaded area represents the 95% confidence interval from a simple regression model.</em></figcaption></figure> <h3>What Do The Embeddings Look Like?</h3> <p>While the cosine similarity difference was an effective quantitative measure of model performance, we explored some qualitative measures to visualise the embeddings and their quality. To interpret the deeper topological information captured embeddings, we used a Uniform Manifold Approximation and Projection (UMAP) model to project the embeddings to a lower, 2-dimensional space. The 2-dimensional projection allowed us to visualise the structure of the embedding space and observe how accounts naturally clustered based on their transactional behaviour.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/586/0*XWlZ6SORrV3M0VvA.png"/></figure> <p>As seen in the image above, the initial investigation using UMAP revealed that the model was clearly able to understand the difference between the different types of nodes on the graph. Each cluster on the plot reflects a distinct pattern of interaction within the transaction network, potentially describing how routine spending, business flows, peer-to-peer transactions, or anomalies are separated when visualised this way. When the population was filtered to display only NatWest accounts, the UMAP plot revealed clusters clearly distinguishing current accounts from savings accounts as seen below.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/586/0*RpEtyAFxYtlBqyes.png"/></figure> <p>This revealed an unexpected similarity in behaviour between savings accounts merchants as they can only interact with current accounts.</p> <p>A deeper investigation into these UMAP projections exposed the model’s ability to capture geographical information of accounts. The next figure shows four density plots where the opacity of each pixel is determined by the number of accounts with their UMAP projection in that region.<br/>Specifically, a darker a pixel indicates more accounts with a UMAP projection belonging to that region. For each plot, the population was filtered based on the postcode area of the branch (namely, in Belfast, Newcastle, Aberdeen and Huddersfield) that the accounts are registered with. The presence of distinctly dark pixels at unique locations in each plot showcases that geographical clustering is induced in the embeddings generated by this model. This is most clearly visible in the plot for Belfast showing over 4% of accounts clustered in the top left corner.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/516/0*V0O4-fb-wrksR1hb.png"/></figure> <p>The presence of these geographical clusters could be attributed to two potential reasons:</p> <ul><li>accounts in similar geographical vicinities will likely share the same merchants for their day-to-day purchases.</li><li>accounts tend to transfer money to other accounts in the same geographical vicinity as them.</li></ul> <p>The model’s ability to induce this information without any prior knowledge of the accounts’ locations, purely based on transaction activity, is a testament to its ability to capture topological information beyond just the connectedness of the network. This information is induced through the transactional behaviours of each account and can be a highly valuable proxy for account information to many downstream applications.</p> <blockquote>Note: UMAP is a dimensionality reduction algorithm and will inevitably not be able to represent all the information contained within the original 32-dimensional embeddings. Nonetheless, they still provide us with a very tangible evidence for the successful training of the model.</blockquote> <h3>Embeddings for Fraud Detection</h3> <p>Because our model is trained in a completely unsupervised way, the embeddings it produces aren’t tied to any one task. This makes them incredibly versatile, allows them to be reused across a wide range of downstream applications that benefit from understanding transactional behaviour. To demonstrate this flexibility, we applied the embeddings to a real-world challenge: detecting money mules. Money mules are individuals who act as intermediaries between suspicious and legitimate accounts, often unknowingly helping to launder money. Identifying them is critical for banks, as they play a key role in concealing the origins of illicit funds and can face serious legal consequences themselves.</p> <p>We tested the value of the embeddings by comparing two versions of a money mule detection model. The first used only traditional account-level features and served as our baseline. The second used the same features but added the 32-dimensional embeddings as additional inputs. We evaluated both models using two key metrics:</p> <ul><li>PR-AUC (area under the precision-recall curve), a way to measure how well the model can identify rare events money mule activity.</li><li>precision@k, measuring how many of the top <em>k</em> predictions made by the model are actually correct.</li></ul> <figure><img alt="" src="https://cdn-images-1.medium.com/max/468/1*vCX2H2wtfNTSU4Yv37f4zA.png"/><figcaption><em>Comparison of results from the two money mule detection models</em></figcaption></figure> <p>While we can’t share the raw numbers due to the sensitivity of the data, the results revealed that the model that included embeddings outperformed the baseline, especially in the top-ranked predictions. In fact, precision among the top 20 flagged accounts improved by 57.1%, a major win for fraud analysts who often have limited time and need to focus on the highest-risk cases.</p> <p>Even though the overall PR-AUC did not change dramatically, this was likely due to the highly imbalanced nature of the dataset. However, it remained stable, confirming that the embeddings did not degrade performance. Instead, they sharpened the model’s ability to prioritise the most critical cases, highlighting their practical value in real-world fraud prevention.</p> <h3>Where Do We Go From Here?</h3> <p>One of the exciting aspects of our approach is that the model can infer fresh embeddings on a regular basis, we currently do this every week. Meaning, we are not just capturing a static snapshot of an account’s behaviour, but rather building a dynamic view of how its transactional neighbourhood evolves over time. Think of it this way: each week, the embedding reflects where an account “lives” in the transaction network during that time. By comparing its embeddings over time, we can understand how that account moves on this network as its behaviour shifts. This can indicate whether it becomes more active, connects with new types of entities, or starts to resemble known risky patterns. This opens the door to an interesting next step: a temporal analysis of embeddings. In financial services, behavioural changes over time are often more telling than static features. A customer who suddenly starts transacting with high-risk accounts or changes their spending patterns dramatically might warrant closer attention. Embeddings give us a compact, data-driven way to track and quantify these shifts.</p> <p>This work also introduces some interesting challenges from a technical perspective. As the size of the transaction network grows, so does the computational demand. Implementing distributed training across multiple GPUs would significantly reduce training time and make it feasible to update embeddings more frequently or at larger scales. A more sophisticated implementation like this could also enable us to use these embeddings in real-time in the future.</p> <p><strong>The network remembers everything. The question is: what will you discover?</strong></p> <p>If you found our work interesting and would like to solve similar problems, we encourage you to take a look at our <a href="https://jobs.natwestgroup.com/pages/technology-digital-data?utm_source=natwestgroup.com&amp;utm_medium=referral&amp;utm_campaign=march_nwg_engineering_blog">available job openings</a>!</p> <p><em>This work has been published in LNCS. For the full academic treatment, check out our paper </em><a href="https://link.springer.com/chapter/10.1007/978-3-031-94139-9_17"><em>here</em></a><em>, we’ll post an arXiv version in early July.</em></p> <h3>References</h3> <p>[1] <a href="https://medium.com/stanford-cs224w/self-supervised-learning-for-graphs-963e03b9f809">Self Supervised Learning for Graphs, <em>Medium</em></a><br/>[2] <a href="https://arxiv.org/abs/1706.02216">Inductive Representation Learning on Large Graphs, <em>arXiv</em></a></p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=62e9b7c5a96d" width="1" height="1" alt=""/>&lt;hr&gt;&lt;p&gt;<a href="https://nwg.ai/the-geometry-of-money-how-we-used-graph-neural-networks-to-transform-financial-network-analysis-62e9b7c5a96d">The Geometry of Money: How we used Graph Neural Networks to transform financial network analysis</a> was originally published in <a href="https://nwg.ai">NatWest Group AI &amp; Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</p>]]></content><author><name></name></author></entry><entry><title type="html">Discover our AI research</title><link href="https://conor-hamill.github.io/blog/2025/discover-our-ai-research/" rel="alternate" type="text/html" title="Discover our AI research"/><published>2025-05-19T14:22:40+00:00</published><updated>2025-05-19T14:22:40+00:00</updated><id>https://conor-hamill.github.io/blog/2025/discover-our-ai-research</id><content type="html" xml:base="https://conor-hamill.github.io/blog/2025/discover-our-ai-research/"><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*xH3ACvn2Y4WivW82n26QJQ.png"/></figure> <h3>2025 publications</h3> <h4><strong>Evaluating the Sensitivity of LLMs to Prior Context</strong></h4> <p>As large language models (LLMs) are increasingly deployed in multi-turn dialogue and other sustained interactive scenarios, it is essential to understand how extended context affects their performance. Popular benchmarks, focusing primarily on single-turn question answering (QA) tasks, fail to capture the effects of multi-turn exchanges. To address this gap, we introduce a novel set of benchmarks that systematically vary the volume and nature of prior context. We evaluate multiple conventional LLMs, including GPT, Claude, and Gemini, across these benchmarks to measure their sensitivity to contextual variations. Our findings reveal that LLM performance on multiple-choice questions can degrade dramatically in multi-turn interactions, with performance drops as large as 73% for certain models. Even highly capable models such as GPT-4o exhibit up to a 32% decrease in accuracy. Notably, the relative performance of larger versus smaller models is not always predictable. Moreover, the strategic placement of the task description within the context can substantially mitigate performance drops, improving the accuracy by as much as a factor of 3.5. These findings underscore the need for robust strategies to design, evaluate, and mitigate context-related sensitivity in LLMs.</p> <p><a href="https://arxiv.org/abs/2506.00069">[2506.00069] Evaluating the Sensitivity of LLMs to Prior Context</a></p> <h4><strong>AUTOSUMM: A Comprehensive Framework for LLM-Based Conversation Summarization</strong></h4> <p>We present AUTOSUMM, a large language model (LLM)-based summarization system to generate accurate, privacy-compliant summaries of customer-advisor conversations. The system addresses challenges unique to this domain, including speaker attribution errors, hallucination risks, and short or low-information transcripts. Our architecture integrates dynamic transcript segmentation, thematic coverage tracking, and a domain specific multi-layered hallucination detection module that combines syntactic, semantic, and entailment-based checks.</p> <p><em>Accepted to the Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Industry Track)</em></p> <h4><strong>How Personality Traits Shape LLM Risk-Taking Behaviour</strong></h4> <p>This research investigates the relationship between personality traits and risk-taking behaviour in Large Language Models (LLMs) using Cumulative Prospect Theory and the Big Five personality framework. The study reveals that most examined LLMs function as risk-neutral rational agents while exhibiting higher Conscientiousness and Agreeableness with lower Neuroticism. Interventions targeting Big Five traits, especially Openness, successfully influence risk-propensity in several models. Advanced LLMs demonstrate human-like personality-risk patterns through optimal prompting, while their distilled variants show limitations in cognitive bias transfer. The research identifies Openness as the most significant factor affecting risk-propensity, consistent with human baselines, and highlights both potential and limitations of personality-based interventions in LLM decision-making.</p> <p><em>Accepted to the Findings of the Association for Computational Linguistics: ACL 2025</em></p> <h4>Application of GraphSAGE in Complex Transaction Networks</h4> <p>We present the practical application of GraphSAGE, an inductive Graph Neural Network framework, to non-bipartite heterogeneous transaction networks within a banking context. We construct a transaction network from anonymised customer and merchant transactions and train a GraphSAGE model to generate node embeddings. Our exploratory work on the embeddings reveals interpretable clusters aligned with geographic and demographic attributes. Additionally, we illustrate their utility in downstream classification tasks by applying them to a money mule detection model where using these embeddings improve the prioritisation of high-risk accounts. Beyond fraud detection, our work highlights GraphSAGE’s adaptability to banking-scale networks, emphasising its inductive capability, scalability, and interpretability. This study provides a blueprint for financial institutions to harness graph machine learning for actionable insights in transactional ecosystems.</p> <p><em>Accepted to the Proceedings of GbR 2025</em></p> <h4>Agent-based Modelling of Credit Card Promotions</h4> <p>In this research work, we develop an agent-based model of the UK credit card market, based on the interactions between lenders and customers. We then show how this model can be used as a tool to explore outcomes of zero-interest credit card promotion strategies under different market scenarios.</p> <p><a href="https://arxiv.org/abs/2311.01901">[2311.01901] Agent-based Modelling of Credit Card Promotions</a></p> <p><a href="https://www.emerald.com/insight/publication/issn/0265-2323">International Journal of Bank Marketing</a>: <a href="https://www.emerald.com/insight/content/doi/10.1108/ijbm-02-2024-0082/full/html">Agent-based modelling of credit card promotions</a></p> <h3>2024 publications</h3> <h4>A Brief Review of Quantum Machine Learning for Financial Services</h4> <p>This review paper examines state-of-the-art algorithms and techniques in quantum machine learning with potential applications in finance. We discuss QML techniques in supervised learning tasks, such as Quantum Variational Classifiers, Quantum Kernel Estimation, and Quantum Neural Networks (QNNs), along with quantum generative AI techniques like Quantum Transformers and Quantum Graph Neural Networks (QGNNs). The financial applications considered include risk management, credit scoring, fraud detection, and stock price prediction. We also provide an overview of the challenges, potential, and limitations of QML, both in these specific areas and more broadly across the field. We hope that this can serve as a quick guide for data scientists, professionals in the financial sector, and enthusiasts in this area to understand why quantum computing and QML in particular could be interesting to explore in their field of expertise.</p> <p><a href="https://arxiv.org/abs/2407.12618v1">[2407.12618v1] A Brief Review of Quantum Machine Learning for Financial Services</a></p> <h3>2023 publications</h3> <h4>Conformal Predictions for Longitudinal Data</h4> <p>In this paper, we present our research into uncertainty calculation for multi-dimensional time-series forecasting, setting a new performance benchmark for the field. These uncertainty estimates allow more informative predictions in areas like demand and stock market prediction and boost the trustworthiness of our forecasts.</p> <p><a href="https://arxiv.org/abs/2310.02863">[2310.02863] Conformal Predictions for Longitudinal Data</a></p> <h4>Modelling customer lifetime-value in the retail banking industry</h4> <p>This research improves the accuracy of customer lifetime value estimation in retail banking through a machine-learning framework. The improved insight from this framework allows accurate identification of high-value customers, informing marketing, relationship management, and business growth strategies.</p> <p><a href="https://arxiv.org/abs/2304.03038">[2304.03038] Modelling customer lifetime-value in the retail banking industry</a></p> <h3>2022 publications</h3> <h4>Offline Deep Reinforcement Learning for Dynamic Pricing of Consumer Credit</h4> <p>In this paper, we train an offline reinforcement learning agent with a static dataset to determine a better loan interest pricing policy. This approach can be applied to other pricing tasks and means risky experimentation in a live environment can be avoided.</p> <p><a href="https://dl.acm.org/doi/proceedings/10.1145/3533271">ICAIF ’22: Proceedings of the Third ACM International Conference on AI in Finance</a></p> <p><a href="https://arxiv.org/abs/2203.03003">[2203.03003] Offline Deep Reinforcement Learning for Dynamic Pricing of Consumer Credit</a></p> <h4>An Introduction to Machine Unlearning</h4> <p>This paper presents a comprehensive review of a wide range of machine unlearning algorithms, which remove the influence of individual observations from models while minimising computational costs. This review standardizes definitions, evaluation methods, and tackles implementation challenges for machine unlearning.</p> <p><a href="https://arxiv.org/abs/2209.00939">[2209.00939] An Introduction to Machine Unlearning</a></p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=fdcdd666c5af" width="1" height="1" alt=""/>&lt;hr&gt;&lt;p&gt;<a href="https://nwg.ai/discover-our-ai-research-fdcdd666c5af">Discover our AI research</a> was originally published in <a href="https://nwg.ai">NatWest Group AI &amp; Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</p>]]></content><author><name></name></author></entry><entry><title type="html">From RAG to Riches — Evaluating GenAI systems and their components</title><link href="https://conor-hamill.github.io/blog/2025/from-rag-to-richesevaluating-genai-systems-and-their-components/" rel="alternate" type="text/html" title="From RAG to Riches — Evaluating GenAI systems and their components"/><published>2025-05-19T13:56:58+00:00</published><updated>2025-05-19T13:56:58+00:00</updated><id>https://conor-hamill.github.io/blog/2025/from-rag-to-richesevaluating-genai-systems-and-their-components</id><content type="html" xml:base="https://conor-hamill.github.io/blog/2025/from-rag-to-richesevaluating-genai-systems-and-their-components/"><![CDATA[<h3>From RAG to Riches — Evaluating GenAI systems and their components</h3> <p><em>By </em><a href="https://www.linkedin.com/in/basit-ali-saeed-a301a98a/"><em>Basit Ali Saeed (Senior ML Engineer, Applied AI)</em></a><em> and <br/></em><a href="https://www.linkedin.com/in/beth-barlow-ejb19/"><em>Beth Barlow (Senior ML Engineer, AI Hub)</em></a></p> <h3>Introduction</h3> <p>In <a href="https://nwg.ai/from-rag-to-riches-how-natwest-is-using-genai-to-unlock-knowledge-across-the-organisation-bda931e2d68a">Part 1</a>, we introduced the RAG (Retrieval Augmented Generation) architecture and how we used it at NatWest Group to build a chatbot that supports our colleagues with domain-specific question answering. The system consists of two core components that contribute to the final output: the information retrieval (IR) process and the generative model.</p> <p>Unlike traditional machine learning tasks where outputs are often (but not always) discriminative, evaluating text can be a challenge. Typically, ground truths are not available to work with, and choosing the right metrics to measure against isn’t always straightforward. This is further complicated in systems that have dependencies on previous steps, such as RAG-based systems. If the retrieval step finds the wrong context, do we penalise the LLM for generating the wrong answer?</p> <p>In this post, we share how we built an evaluation framework that separates the components within a RAG architecture to deal with the challenges of evaluating an LLM-based system.</p> <h3>Automated Evaluation</h3> <p>This section covers how we generated synthetic data and used a set of automated metrics to understand the performance of the IR and LLM response generation components.</p> <h4>Creating Synthetic Test Sets</h4> <h4>Overview</h4> <p>Similar to traditional machine learning tasks, the distribution of your test set should be as close to real-world data as possible. This gives you confidence that the performance of your model in the real world will be similar to that on your test set. The same notion can be extended to natural language tasks as well; domain-specific datasets are much more likely to give an indication of model performance than general benchmarks.</p> <p>Our application is designed to act as an assistant to NatWest Group employees, helping answer questions relating to internal processes. We therefore needed a test set developed in-house. Whether evaluating retrieval performance or LLM response quality, the majority of metrics require a ‘ground truth’, that is, the expected result produced by the system component. These labelled datasets are very labour-intensive to create, and at the time of testing, nothing suitable existed for our domain. We therefore decided to create a dataset comprising of synthetically generated samples ourselves.</p> <h4>Step 1: Generating Questions and Answers</h4> <p>In Part 1 of the blog, we described our hybrid search process that retrieves document chunks stored in our vector database. These chunks are designed to be contextually disparate, with the aim of improving search efficiency as well as organizing the knowledge base in a structured manner.</p> <p>We can further leverage the stored chunks to create synthetic question-answer pairs. To achieve this, we fed individual chunks into an LLM, alongside instructions to produce a single question and answer using the information contained in the chunk. To ensure the balance of this overall dataset, a stratified sample (relative to the document size/number of chunks) was used to avoid over-testing on specific content.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*j1hAykHY89MVmrh9v-X6qg.png"/><figcaption><em>A stratified sample of chunks was used to build a test set.</em></figcaption></figure> <p>Depending on the LLM, experimentation with the prompt is often required to generate questions of realistic tone, complexity, and brevity. There are some challenges in using this method, particularly in generating realistic questions that are highly related to the source chunk whilst introducing differences in vocabulary. To ensure a high quality final test set, we wrote data cleaning checks that included removal of questions that were duplicated, showed a high token-based similarity to their source chunk, or showed a poor semantic relevance to their source chunk. It is important to note, however, that we included questions that were deliberately noisy or vague to test the robustness of the system.</p> <p>The generated answers from this process are ultimately considered ground truths against which to compare responses generated by the full RAG system.</p> <h4>Manually curated questions</h4> <p>In addition to the LLM-generated question-answer pairs, we also manually created several sets of specific question-answer pairs that weren’t associated with any of the document chunks. This was motivated by identifying specific types of questions for which we sought to improve the model’s response. For example, one set contained only ‘off-topic’ questions that were unrelated to company policies, whilst another contained vague and incoherent inputs. In both cases, the desired response is a refusal to answer. Tags were created for these targeted question types to allow us to filter the final aggregated test set and evaluate system performance across different facets. LLM-generated questions were also tagged as such for identification.</p> <h4>Step 2: Generating Retrievals</h4> <p>RAG-based question-answer systems require an input question, as well as a retrieved context. This context is a collection of the N most relevant chunks, and due to this, often contains noise surrounding the information required to provide the answer. Therefore, to replicate the expectations of using a RAG system, we fed the final set of test questions (synthetic and manually created) into the IR pipeline and returned N relevant chunks.</p> <p>It’s also important to note that despite having no associated chunk, we nevertheless retrieved context for the manually curated questions. The reason for this is to understand whether the target output behaviour defined in the system prompt is affected by the context.</p> <p>The outcome of this retrieval generation step was the creation of a dataset containing question-answer-context triplets that can be used to evaluate the RAG system.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/953/1*yKFnlcTh-sdiFPW4LHFR7g.png"/><figcaption><em>Context chunks were retrieved for each question using our existing IR pipeline.</em></figcaption></figure> <h4>Evaluation of the Information Retrieval (IR) system</h4> <p>To fully optimise the IR system, having a robust setting in which to evaluate the results is essential. Generally, evaluation involves curating a test set of representative questions and results, along with assigned ‘relevance ratings’ that reflect how relevant each returned result is to the question. Such a test set can be used to calculate several key quantitative performance metrics. These include well-known machine learning metrics such as precision and recall, as well as more advanced metrics such as Mean Reciprocal Rank (MRR), which captures the position of the first relevant chunk in the results list, and Normalised Discounted Cumulative Gain, which given a graded rating scale (e.g. 0, 1, 2), captures the overall ranking order and the system’s ability to understand relative relevance.</p> <p>Curating a dataset with manually assigned relevance ratings requires significant manual effort and subject matter expertise. For this reason, our approach leveraged the synthetic dataset described above, comprising question-context-answer triplets. We measured retrieval performance as the ability of the system to retrieve the chunk used to generate the question. In the list of results, we considered this chunk relevant (i.e., rating 1) and all others irrelevant (i.e., rating 0). This allowed us to calculate Recall, which is the percentage of questions for which the relevant chunk is returned, and Mean Reciprocal Rank, which is a measure of the average position of the relevant chunk in the retrieval results. These metrics are intuitive and powerful. The former broadly captures the percentage of ‘correct’ contexts provided to the LLM. The latter provides a more detailed insight into the ability of the retriever to detect semantic nuances beween chunks and therefore rank results by relevance.</p> <p>The evaluation pipeline is flexible and allows efficient tuning of retrieval-based hyperparameters. Two key areas of focus for us were the embedding model and the hybrid search mechanism, including number of search results and choice of re-ranking method. Our decision to use a re-ranker model was based on experiments comparing this method against popular traditional ranking mechanisms such as Reciprocal Rank Fusion and CombSUM.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/970/1*FDDKahSGyavOTZzge98-Ww.png"/><figcaption><em>A simple calculation of recall for a system retrieving chunks for only two questions. The ‘correct’ chunk is highlighted in green.</em></figcaption></figure> <h3>Evaluation of the LLM for Response Generation</h3> <p>For response evaluation, we leveraged the synthetic question-context-answer triplets, and this time filtered the dataset to ensure that the chunk used to generate the question-answer pair was present within the retrievals, removing all samples where this was not the case. Based on this, we can (safely) assume that the model has enough information to effectively answer the input questions.</p> <p>At this stage, we have a test set that, in a traditional machine learning sense, we need to generate predictions for. This was achieved by passing a system prompt to the LLM in addition to the user prompt containing the question and context.</p> <p>To evaluate the ‘correctness’ of the resulting responses, we measured the difference between these responses and the associated desired answers, that is, the ground truths generated from the chunk samples. Two metrics were used to achieve this:</p> <ul><li><strong>Semantic similarity score</strong>: we encoded both the ground truth and generated answer into vector representations that aim to capture the semantic information. Following this, we computed the cosine similarity between the two vectors to get a score representing their similarity in meaning. This method is optimal for the majority of response comparisons as it allows for flexibility in what is considered a ‘correct’ response.</li><li><strong>BLEU score</strong>: BLEU (Bilingual Evaluation Understudy) is a metric that was initially introduced to evaluate text in machine translations tasks, leveraging n-gram (often sequences of words) matches. As our outputs are relatively short, we defined the n-gram match to 2, effectively scoring on bigram matches. BLEU scoring is particularly useful when an exact phrase match is desirable, for example for the manually created questions where we deliberately constrain the LLM to provide a fixed, precisely-worded refusal response.</li></ul> <p>After scoring the test set, we were able to use the question-type tags created initially to apply the two evaluation metrics to where they are more suited. These metrics allowed us to assess the performance of the system for different question types, e.g. standard questions, off-topic questions etc. and thereby hone areas of the system that are performing below expectation.</p> <p>This evaluation framework is proving powerful in enabling the team to rapidly iterate and test prompts and assess how they affect performance. It’s important to note that human input isn’t entirely removed, and indeed review is often required to understand nuances, in particular ensuring that low scores are justified and align with human preference.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1012/1*xTMhR6e9-ITBxI0dXd15Sg.png"/><figcaption><em>Evaluation of the generated response from the RAG-based LLM using two metrics.</em></figcaption></figure> <h3>Human Evaluation</h3> <h4>Motivation</h4> <p>Manual review of questions and answers from an LLM-based chatbot is the gold-standard method of ensuring safe, accurate and consistent responses. Humans can capture nuances in LLM responses that simple string-based accuracy metrics cannot. This level of detail is crucial in order to be able to confidently promote a RAG system to a production environment with live users. In line with staged releases of our knowledge base content, a round of human evaluation was carried out prior to each release.</p> <h4>Creating a Test Set</h4> <p>Unlike automated evaluation, human evaluation doesn’t require intricate creation of synthetic test sets. Instead, the purpose is to evaluate how well the system handles real user queries that are entirely representative of what the system will face in production. By nature, these questions are varied in topic, length, style, and comprehensibility, and introduce edge cases that would be extremely difficult to anticipate or mimic in a synthetic test set. This is ideal for stress-testing the developed system prompt.</p> <p>To create test sets for human review, we gathered random samples of 50–100 relevant questions that had been sent to the existing pre-RAG chatbot in previous years. The questions were specific to the topic(s) that were due to go live in the upcoming release cycle. We generated context and a response for each question, to produce a dataset of question-context-answer triplets.</p> <h4>Review Process</h4> <p>To gain a comprehensive view of the quality of an LLM response, we developed a series of criteria-based metrics on which to score the response. These were faithfulness, truthfulness, relevance, completeness, fluency and bias. There is no one-size-fits-all approach to selecting these metrics, and ours were motivated by industry best practices along with alignment to the system prompt instructions. Each metric was associated with a scoring rubric; a score range and supporting guidelines that were carefully written to capture the particular nuances of our chatbot use case.</p> <p>An example rubric for the ‘faithfulness’ metric is as follows:</p> <ul><li><strong>Score of 0: </strong>The answer contains information that cannot be found anywhere in the question or context. This information would have a negative material impact on the colleague.</li><li><strong>Score of 1:</strong> The answer contains information that cannot be found anywhere in the question or context. This information is true, harmless and would have no material impact on the colleague.</li><li><strong>Score of 2: </strong>All information from the answer has been taken from the question or context. Include refusals to answer the question.</li></ul> <p>For each round of human evaluation, we recruited a team of subject matter experts with strong knowledge of the underlying content. The results were aggregated across labellers and analysed on a per-response level to understand which samples were concerning and warranted further investigation. We also calculated the aggregate <em>agreement</em> for each criteria-based metric to signal any disagreements that could make the results unreliable.</p> <h3>Further Improvements</h3> <h4>More Representative Data</h4> <p>There are several approaches to generating test sets, which see a trade-off between manual curation effort and dataset quality.</p> <p>Synthetic data has several benefits including its scalability, ability to be tailored to specific needs, and mitigating privacy concerns. However, there are a couple of downsides. Firstly, the questions generated are not entirely representative of real-life. Human-generated inputs can contain grammatical and spelling mistakes, colloquial language and a mixture of questions and statements, with it being difficult to capture this diversity by LLM-generation. Secondly, by considering the chunk from which the question was generated as the <em>only</em> relevant chunk, we lose a large amount of information about the overall quality of the retrieved context, in addition to the ability of the system to assess relative relevance in the ranking order.</p> <p>The quality of synthetic question-answer pairs generated largely depends on the clarity of instruction within the prompt, and the LLM’s capabilities. Continued advances in the field of natural language generation lead to the possibility of creating higher quality data — specifically with models fine-tuned for this task. It therefore becomes an important avenue of further work to explore innovative approaches to synthetic data generation, in order to more accurately replicate the complex patterns and relationships in real-world data.</p> <p>Alternatively, to avoid the issue in considering the source chunk as the only relevant chunk, methods exist to create real labelled test sets. The most robust method is to select a set of real user queries for which all relevant document chunks are identified in advance and can be marked by relative relevance. This dataset can be compared to the results generated by the retrieval system to calculate evaluation metrics. In doing so, we can better capture the system’s ability to order results by relative relevance, and find chunks of similar relevance from across the knowledge base. Although the dataset requires a larger up-front effort to curate, it can be augmented over time by high quality samples gathered through the production system.</p> <h4>Towards LLM-as-a-Judge</h4> <p>The use of LLM Judges to function as proxies for labelling teams in the human review process has become increasingly common and we developed an internal re-usable package to implement the technique. In doing so, we can produce a system that achieves a similar level of scalability and efficiency as the automated evaluation explained previously, whilst maintaining a more rounded view of LLM response quality.</p> <p>However, LLMs have inherent biases and using one to evaluate another may propagate that bias through the system. One of the most significant challenges we faced was engineering the LLM Judge prompts to achieve good alignment between human and LLM Judge scores. This was particularly difficult for more subjective metrics such as ‘completeness’ and ‘relevance’. These metrics are based on how a given judge interprets the question’s intent and considers which extracts in the context are relevant. In addition, we needed the judge to handle edge cases, including refusals to answer the question. We developed human-labelled benchmark test sets and used agreement metrics such as percentage agreement to ensure that our LLM Judge outputs were not skewed or showed unexpected behaviours in edge cases.</p> <p>LLM-as-a-Judge is a promising method, and we are confident that with the recent rise of reasoning models and greater understanding of fine-tuning, we will be able to achieve a high level of reliability and human-alignment in future iterations.</p> <h3>Conclusion</h3> <p>Evaluating LLM-based systems is a complex field and there is no one-size-fits-all approach. For our RAG-based application, we employed a combination of automated metric calculation and human review to evaluate the core components of the system. Whilst human evaluation is still the gold standard, it is simply not feasible at scale with limited resources. Leveraging the automated framework above, we were able to quickly iterate on prompts and other system parameters, whilst gaining a directional understanding of how each component affects system performance.</p> <p>It’s pertinent to highlight that the evaluation tooling operates outside the main RAG-based application and communicates with the RAG component via the REST API. This ensures that the system being evaluated is identical to the production solution, and permits us to experiment with greater freedom without impacting the end-user experience.</p> <p>As the field of Generative AI continues to expand and we move into worlds of agent-based systems and multi-modal models, our evaluation methods will also need to evolve. This blog post introduces some important foundational techniques and we will continue to build on these as our toolkit improves with more powerful, and fine-tuned models. Keep an eye out for more posts coming later this year!</p> <p>Finally, if you found our work interesting and would like to solve similar problems, we encourage you to take a look at our <a href="https://jobs.natwestgroup.com/pages/technology-digital-data?utm_source=natwestgroup.com&amp;utm_medium=referral&amp;utm_campaign=march_nwg_engineering_blog">available job openings</a>!</p> <p><em>The views and opinions expressed in this article are those of the author and do not necessarily represent the views of the NatWest Group.</em></p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=7dea97380fcd" width="1" height="1" alt=""/>&lt;hr&gt;&lt;p&gt;<a href="https://nwg.ai/from-rag-to-riches-evaluating-systems-and-their-components-7dea97380fcd">From RAG to Riches — Evaluating GenAI systems and their components</a> was originally published in <a href="https://nwg.ai">NatWest Group AI &amp; Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</p>]]></content><author><name></name></author></entry><entry><title type="html">From RAG to Riches — How NatWest Group is using GenAI to unlock knowledge across the organisation</title><link href="https://conor-hamill.github.io/blog/2025/from-rag-to-richeshow-natwest-group-is-using-genai-to-unlock-knowledge-across-the-organisation/" rel="alternate" type="text/html" title="From RAG to Riches — How NatWest Group is using GenAI to unlock knowledge across the organisation"/><published>2025-05-09T14:39:31+00:00</published><updated>2025-05-09T14:39:31+00:00</updated><id>https://conor-hamill.github.io/blog/2025/from-rag-to-richeshow-natwest-group-is-using-genai-to-unlock-knowledge-across-the-organisation</id><content type="html" xml:base="https://conor-hamill.github.io/blog/2025/from-rag-to-richeshow-natwest-group-is-using-genai-to-unlock-knowledge-across-the-organisation/"><![CDATA[<h3>From RAG to Riches — How NatWest Group is using GenAI to unlock knowledge across the organisation</h3> <p><em>By </em><a href="https://www.linkedin.com/in/michaelengland91/"><em>Michael England (Lead Software Engineer, Applied AI)</em></a><em> and <br/></em><a href="https://www.linkedin.com/in/james-thurgood-21ba4a10b/"><em>James Thurgood (Lead ML Engineer, Applied AI)</em></a></p> <p>A common problem across large enterprises is providing employees access to the right data when they need it and in an easy to consume format. Important information is often stored across thousands of PDF files, Microsoft Word documents and intranet pages, making it difficult for employees to find.</p> <p>Last year, <a href="https://www.natwestgroup.com/news-and-insights/latest-stories/ai-and-data/2024/aug/simplifying-our-colleague-experience-with-gen-ai.html">we announced how we took steps to help solve this problem, by bringing the power of GenAI to our colleague chatbot, Ask Archie</a>. In this post, we expand upon the techniques we used, highlight our learnings after almost a year running in production, and discuss how we are looking to scale similar GenAI systems across the organisation.</p> <h3>Giving generative AI access to your knowledge</h3> <p>Generative AI chatbots have taken the world by storm since the launch of <a href="https://chat.openai.com/">ChatGPT</a> by OpenAI in November 2022. Powered by LLMs, generative AI chatbots can answer complex user questions, create new content, and even reason through problems.</p> <p>However, LLMs such as the <a href="https://ai.meta.com/llama/">Llama</a> and GPT family of models are limited to the knowledge that they acquired during the training phase. These models work well at answering generic questions, such as “what is the role of AI in providing information?”, however if they are prompted to answer a question outside of their training data, they often refuse to answer, or worse, hallucinate and answer incorrectly. This is where Retrieval Augmented Generation (RAG) comes into the picture.</p> <p>RAG is an architecture, <a href="https://ai.meta.com/blog/retrieval-augmented-generation-streamlining-the-creation-of-intelligent-natural-language-processing-models/">popularised by Meta in 2020</a>, that combines information retrieval and a generative AI model. The idea is simple — when a user enters some text e.g. “I am travelling to London on Monday and returning Friday, how much can I expense for dinner each night?”, the application first fetches relevant text from source systems and then includes this within the context of the LLM text prompt. In this example, relevant text could be passages from an internal travel and expenses policy. The LLM will then utilise both the knowledge learned from its training data (encapsulated by its model weights) and the knowledge provided in the retrieved text to generate an output.</p> <p>Here is an example prompt that could be used in this scenario:</p> <pre>You are an assistant that helps company employees answer questions on internal policy documents.<br />Given the following extracted parts of the documents and a question, create a final answer.<br />Be brief in your answers.<br />Answer ONLY with the facts listed in the list of sources below.<br />If there is not enough information below to answer the question, say you don&#39;t know.<br /><br />QUESTION:<br />[USER QUESTION]<br /><br />CONTEXT:<br />[RETRIEVED DOCUMENT TEXT]<br /><br />ANSWER:</pre> <p>The RAG architecture is ideal for unlocking information across large corpuses of documents. Accurate information retrieval can be utilised to pull out relevant passages of documents and generate legible answers to user queries within a few seconds, saving many employee hours. The user experience is also improved, as rather than trawling multiple pages you are presented with a summary with the ability to ask follow up questions for better understanding.</p> <h3>Architecting a RAG solution</h3> <p>At NatWest Group, we had the challenge of integrating RAG within an existing Natural Language Understanding (NLU) based chatbot called Ask Archie. The most straightforward approach was to build out the RAG component as a microservice that the existing Ask Archie system could communicate with via a REST API. Here is a simplified diagram of how the various components fit together:</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*HvYnnTX7TVwjW6OLQEwzvA.png"/><figcaption>The system’s high-level RAG architecture</figcaption></figure> <p>The initial call to the RAG microservice is made when the Ask Archie chatbot system decides the user input requires a generated response. Once a HTTP request is made to the RAG microservice REST API, the system immediately performs guardrail checks on the user input. This ensures that the input is safe from a content moderation and security (jailbreak and prompt injection) perspective, as defined in a guardrail policy.</p> <p>Assuming the input is deemed safe, the information retrieval stage is initiated. Initially, a hybrid search is executed against the document database to try and retrieve the most relevant parts of the source documents to answer the user query. This comprises of two components:</p> <ul><li>A <strong>semantic search query</strong>, which utilises a vector embedding generated from the user input to perform a nearest neighbour search, using the PGVector extension for the PostgreSQL database. This query will identify documents that are similar in meaning to the user’s search query. For example, if a user searches for vacation allowance, but the source documents mention holiday allowance, the semantic query will likely understand that these terms are interchangeable and will return the correct documents.</li><li>A <strong>keyword search query</strong> which aims to return documents which contain keywords (or parts of keywords) that the user is searching for. This can be especially useful when the user’s query contains specific company-specific acronyms that the similarity search may not pick up.</li></ul> <p>The two queries executed by the hybrid search provide the system two sets of results containing document chunks which are potentially relevant to the user’s search query. These queries are very fast to execute, however they are not the most accurate. We can think of these queries acting as a broad search, but we need a mechanism to combine these results and rank them in order of the relevance to the question.</p> <p>The next step is to perform result re-ranking, where a cross-encoder model is used to decide how relevant each retrieved chunk is to the user’s input query. The cross-encoder model is much more accurate compared to the approaches the initial queries used, with the trade off that it is slower. However, given it only needs to operate on the small subset of results returned by the hybrid search queries, it can be used as part of this architecture.</p> <p>Once the scores have been calculated, the result list is ordered from most to least relevant, and a minimum-score threshold and final result limit is applied. The final result list should contain the most relevant document chunks the LLM can use to answer the user question.</p> <p>The generation step is more straightforward — the retrieved chunks are combined into a single LLM prompt along with the system instructions and user question. The chat LLM then generates an answer, which is passed via the guardrail service to check for any content moderation breaches before being returned in the response.</p> <h3>Tracking Performance And Identifying Issues</h3> <p>Given the flexible nature of LLMs, it is important to keep track of how we utilise them and how they perform, both from a functional and non-functional point of view.</p> <p>There are many possible data points that can be tracked. For example:</p> <ul><li>Original user question</li><li>LLM response</li><li>User feedback on the response (positive/negative)</li><li>Full prompt text (including retrieved documents as context)</li><li>LLM errors</li><li>Hyperparameters</li><li>Request latency</li><li>Number of input and output tokens</li></ul> <p>Providing access to this data via dashboards enables the development team to quickly identify where the LLM is not working as expected and replay failures or poorly performing questions using the stored data.</p> <p>For example, by reviewing the logs, we have been able to identify gaps in our underlying documentation, with users asking questions and the retrieval results coming back empty or with a low relevancy score. This has allowed us to focus on improving specific areas in ongoing content updates.</p> <p>These logs have also allowed us to keep a close eye on latency. RAG systems are complex with many moving parts which could all lead to bottlenecks, and every millisecond counts when you have a user on the other end of the keyboard awaiting a response. Keyword search, semantic search, re-ranking, LLM queries and LLM moderation are complex processes which all play their part in the overall time taken to respond to a user. Through close observation of these metrics we have been able to identify specific bottlenecks and focus resource on improving that component’s efficiency.</p> <h3>Learnings from production</h3> <p>While non-production environments are valuable for the initial testing and validation of a solution, nothing compares to the insights you get from running real-world workloads. Our solution has now been in production for nine months, during which we have been able to evaluate the performance of the system against millions of real-world queries, identify areas of the system that could be improved and develop new learnings as we have iterated on key system components. In this section, we will dive into some key learnings we have identified since we deployed the solution in production.</p> <h4>Changing models is difficult</h4> <p>As new LLMs are released, third-party model providers aim to deprecate older versions of models to free up their hardware. The impact of this is that systems have to be upgraded to a new model version approximately every 6–9 months. Model upgrades inherently come with a number of risks, and therefore to mitigate these, automated test suites and frictionless human evaluation processes are a must for production services utilising LLMs.</p> <p>To shine a light on why changing models can be difficult with a real example, the microservice originally used OpenAI GPT-3.5 Turbo v1106 as the core chat LLM. After a few months this version was scheduled for retirement, and the system had to be upgraded to use a new patch version of this model, v0125. Our evaluation processes picked up that with no prompt changes, the new model refused to answer the user question based on the context retrieved in 16% of cases across a number of topics, significantly more than the previous model version. To fix this, the prompt had to be re-engineered to follow a few-shot approach, resulting in a 7% reduction of answer refusals compared to the original model.</p> <p>As the above example highlights, changing models can be a very time consuming process and adds additional workload and risk to teams managing LLM solutions. Self-hosting models is an alternative option which can remove the dependency on third-party model retirement dates, with the trade off of additional cost and complexity.</p> <h4>The wider industry moves at pace</h4> <p>It isn’t just LLM providers that are innovating. The wider GenAI community is continuously innovating and shipping new products. Whether it is a new data store, agent framework, pattern or managed service, there are continuous innovations that you need to keep up with to ensure your product continues to improve.</p> <p>When building out GenAI services at NatWest Group, it has been an important focus of ours to ensure that we can swap out individual system components where required. This can be the underlying data stores, embedding models, chat models and so on.</p> <p>A key component which has enabled teams to move at pace has been the introduction of the NatWest AI platform. This provides a gateway that applications can use to connect to a catalogue of models from different providers, so teams can easily switch to the best model for their use case without large architectural changes. The same platform which is an evolution of the <a href="https://aws.amazon.com/blogs/machine-learning/part-1-how-natwest-group-built-a-scalable-secure-and-sustainable-mlops-platform/">one described here</a> also allowed the team to deploy re-ranking models with ease to AWS. This provided us the ability to switch to other leading re-ranking models as the open source community innovated.</p> <h4>Collaboration between all engineers is key</h4> <p>We identified early on that we needed to remove any barriers between data scientists/ML engineers who were building and iterating on ML-related components and software engineers who were building out the production APIs and services.</p> <p>During the initial RAG microservice build out, the DS/ML team members replicated the functionality of the main service so that they could run experiments locally and iterate on data, prompts and models. This was partly due to the DS/ML teams working on a different stack to the software engineers. This quickly became unwieldy as the setups diverged. It became apparent that we needed to identify a way for the DS/ML team members to iterate on individual parts of the system, whilst the rest of the functionality stayed in-line with the main production service.</p> <p>We ended up enabling a number of experimental attributes in the request body of our service, so users could override individual parts of the RAG functionality. These were only enabled in non-production, but supported tuning parameters such as:</p> <ul><li>The system and user prompts for the main Q&amp;A flow</li><li>The system and user prompts for rephrasing the user’s question based on past input</li><li>The LLM used for question rephrasing and answering</li><li>The re-ranking model along with the ability to tune the re-ranking score threshold</li><li>Result limits, including the ability to tune the number of results returned from each data store query</li></ul> <p>Evaluation pipelines were then built which took advantage of these attributes. This unlocked the ability for the team to experiment with small changes to the RAG microservice extremely quickly.</p> <p>To bring this to life, here is an example of a request body sent to the RAG microservice including experimental parameters:</p> <pre>{<br />    &quot;sessionId&quot;: &quot;&quot;,<br />    &quot;interactionId&quot;: &quot;&quot;,<br />    &quot;query&quot;: {<br />        &quot;content&quot;: &quot;What is NatWest&#39;s policy for partner leave, how many days am I entitled to?&quot;,<br />        &quot;documentCollection&quot;: ...,<br />        &quot;messageHistory&quot;: ...,<br />        &quot;retrievalResultLimit&quot;: ...,<br />        &quot;minRetrievalResultScore&quot;: ...,<br />        &quot;reRankerType&quot;: ...<br />    },<br />    &quot;additionalContext&quot;: {<br />        &quot;location&quot;: &quot;United Kingdom&quot;<br />    },<br />    &quot;modelProvider&quot;: ...,<br />    &quot;modelName&quot;: ...,<br />    &quot;customPrompts&quot;:{<br />        &quot;questionAnswer&quot;: {<br />            &quot;systemPrompt&quot;: ...,<br />            &quot;userPrompt&quot;: ...<br />        },<br />        &quot;rephrase&quot;: {<br />            &quot;systemPrompt&quot;: ...,<br />            &quot;userPrompt&quot;: ...<br />        }<br />    }<br />}</pre> <h4>Clarify non-functional requirements early</h4> <p>It is important to identify non-functional requirements early on, especially those around model latency and throughput. Due to the limited availability of GPUs globally, your workloads may end up requiring the use of Provisioned Throughput Units (PTUs) to guarantee capacity when you need it. PTUs are expensive, and a system using a PTU will often be spending significantly more on inference than if it was using an on-demand plan. The cost-benefit ratio might not justify proceeding with the project if these are necessary.</p> <p>It is worth analysing whether your applications really need an immediate response from an LLM, or if the model can be called asynchronously instead. This allows you to work around provider rate limits and perform retries where necessary, allowing you to utilise models on-demand. Use cases which send a large number of LLM requests are also likely to benefit from batch APIs which have been made available by many providers at a much reduced cost.</p> <h4>Automation shortens the time to value</h4> <p>A key challenge is always how can we shorten the route to live for our projects. At NatWest Group, our engineers lean heavily on GitLab to reduce time to value, making use of automated pipelines to provide quick feedback and deploy changes into hosting environments.</p> <p>Given our experience of using GitLab across our projects, we decided to use it as an end-to-end content management system for managing the underlying documents that the RAG microservice uses to answer colleague questions.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/690/0*U9-ypcNUFwwMosAb.png"/><figcaption>The high-level document ingestion process</figcaption></figure> <p>GitLab felt like a natural fit for this use case given it provides feature such as:</p> <ul><li>An audit history of changes</li><li>Review/diff functionality</li><li>CI/CD pipelines</li><li>A Web IDE where quick changes can be made</li></ul> <p>We found through experimentation that using well-structured Markdown files for our documents helped us achieve the level of accuracy we required to provide this solution to our NatWest colleagues. Markdown files can be displayed and edited inside of GitLab very easily, and this has allowed the teams that manage content to follow a software development-style workflow. Content modifications are made in feature branches and changes are automatically verified by a GitLab CI process. Following verification, the changes are reviewed by a colleague in a Merge Request, before finally being deployed directly into a data store once it has been approved and merged.</p> <p>This approach means a content change is automatically deployed to a test environment within a few minutes, and shortly after into production, allowing teams to deliver new content at pace.</p> <h3>Future</h3> <p>Leveraging LLMs within a RAG architecture has yielded tremendous benefits, enabling the Ask Archie chatbot to provide natural and targeted responses to colleague questions around a wide variety of topics. Whilst this project has been a success, there is still a lot we are planning to explore.</p> <p>Firstly, we are going to look at how we can scale RAG across the organisation. Ask Archie is just one example of a system where RAG can be applied, and we are taking steps to make it easy for teams to spin up RAG infrastructure with the aim of reducing cost and complexity of these solutions going forward, especially now the industry has caught up!</p> <p>Another interesting area for exploration is fine-tuning language models for improved performance. Internally we have a lot of experience with fine-tuning deep learning models, and we plan to utilise this to fine-tune LLMs. We have found that there is potential to improve information retrieval and answer performance by using domain-tuned models. While many off-the-shelf pretrained embedding models do perform well, fine-tuning against a relevant dataset has the potential to significantly improve the performance of semantic search. Our application is also capturing valuable user question and AI answer data which we will look to use for fine-tuning in future.</p> <p>We will also be looking to utilise more self-hosted models going forward. The pace of open source model development is incredible, and utilising these models would enable us to decouple ourselves from third-party model retirement schedules. We already have experience hosting open source models in our Amazon SageMaker-based ML platform, and will likely be expanding the number of models we self-host over the coming year. These models will be exposed via our NatWest AI platform alongside third-party models for consumption across the organisation.</p> <p>Lastly, LLM evaluation is a topic that we are spending a lot of time on and <a href="https://nwg.ai/from-rag-to-riches-evaluating-systems-and-their-components-7dea97380fcd">warrants its own blog post</a>. As we move between different embedding and chat models, whether they are completely new models or upgrades of the same models, we need to run automated evaluation test suites to provide a level of certainty that overall model performance does not decline. We have deployed LLMOps tooling internally which will help us iterate on our LLM-based systems with confidence, similar to how we utilise MLOps practices for our standard machine learning models. We expect these tools to mature rapidly over the coming year.</p> <p>This is a fast-moving and fascinating area, and we are only just getting started! We aim to publish further blog posts around our journey into the world of generative AI later this year.</p> <p>If you found this blog post interesting and would like to work on similar problems, we encourage you to take a look at our <a href="https://jobs.natwestgroup.com/pages/technology-digital-data?utm_source=natwestgroup.com&amp;utm_medium=referral&amp;utm_campaign=march_nwg_engineering_blog">available job openings</a>!</p> <p><em>The views and opinions expressed in this article are those of the author and do not necessarily represent the views of the NatWest Group.</em></p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=bda931e2d68a" width="1" height="1" alt=""/>&lt;hr&gt;&lt;p&gt;<a href="https://nwg.ai/from-rag-to-riches-how-natwest-is-using-genai-to-unlock-knowledge-across-the-organisation-bda931e2d68a">From RAG to Riches — How NatWest Group is using GenAI to unlock knowledge across the organisation</a> was originally published in <a href="https://nwg.ai">NatWest Group AI &amp; Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</p>]]></content><author><name></name></author></entry><entry><title type="html">NatWest Group AI team at NeurIPS 2024</title><link href="https://conor-hamill.github.io/blog/2025/natwest-group-ai-team-at-neurips-2024/" rel="alternate" type="text/html" title="NatWest Group AI team at NeurIPS 2024"/><published>2025-05-09T14:31:00+00:00</published><updated>2025-05-09T14:31:00+00:00</updated><id>https://conor-hamill.github.io/blog/2025/natwest-group-ai-team-at-neurips-2024</id><content type="html" xml:base="https://conor-hamill.github.io/blog/2025/natwest-group-ai-team-at-neurips-2024/"><![CDATA[<p><em>By </em><a href="https://www.linkedin.com/in/conor-hamill/"><em>Conor Hamill (Senior Data Scientist, AI R&amp;D)</em></a></p> <p>In the fast-evolving world of technology and financial services, one thing is clear: the pace of advancement in AI has been nothing short of astonishing. With the annual publication of AI research papers soaring, we are witnessing capabilities that seemed far-fetched just a few years ago now being integrated into everyday workflows for individuals and businesses alike. The ideas and innovations in cutting-edge techniques in machine learning and AI from academia and industry are vividly showcased at international conferences like NeurIPS, often hailed as one of the largest and most influential gatherings in the realm of machine learning and AI.</p> <p>It was great to see NatWest Group as a bronze sponsor of NeurIPS 2024, with Conor Hamil and Raad Khraishi representing the bank during the week-long conference in December.</p> <h3>Exploring a wealth of research at NeurIPS</h3> <p>NeurIPS 2024 was held in the Vancouver Conference Centre, with the city nestled between the mountains and the sea serving as an inspiring environment for the conference.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/432/0*OzPTm9W3rGaNDiF7.jpeg"/><figcaption>The Vancouver Conference Centre.</figcaption></figure> <figure><img alt="" src="https://cdn-images-1.medium.com/max/426/0*fMbf0cihNfRgk70w.jpeg"/><figcaption>The welcome talk for NeurIPS 2024.</figcaption></figure> <p>Unsurprisingly, large language models (LLMs) were a major focal point of this year’s conference, with many ground-breaking studies addressing key challenges and advancements in this area. Researchers explored mitigating hallucinations in outputs (<a href="https://openreview.net/forum?id=1Fc2Xa2cDK&amp;referrer=%5Bthe%20profile%20of%20Fred%20A.%20Hamprecht%5D(%2Fprofile%3Fid%3D~Fred_A._Hamprecht1)">Truth is Universal: Robust Detection of Lies in LLMs</a>), in-depth studies predicting the emergence of abilities during pre-training (<a href="https://openreview.net/forum?id=On5WIN7xyD">Observational Scaling Laws and the Predictability of Language Model Performance</a>), and optimising prompts for tasks (<a href="https://openreview.net/forum?id=FLNnlfBGMo">Efficient Prompt Optimization Through the Lens of Best Arm Identification</a>).</p> <p>Simultaneously, there was a huge focus on maintaining the same performance of LLMs while reducing the amount of compute (<a href="https://openreview.net/forum?id=manHbkpIW6">Once Read is Enough</a>), training data (<a href="https://openreview.net/forum?id=0NMzBwqaAJ">Not All Tokens Are What You Need for Pretraining</a>), and model parameters (<a href="https://proceedings.neurips.cc/paper_files/paper/2024/hash/ab6eba9a853087993addff937c8cec87-Abstract-Conference.html">Towards Next-Level Post-Training Quantization of Hyper-Scale Transformers</a>) required. Progress in these endeavours is essential for developing faster, more cost-effective models and enhancing computing capabilities on edge devices.</p> <p>The development of LLM agents using these LLMs made up a large amount of the work in the conference. This included works exploring different workflows of LLM agents (<a href="https://proceedings.neurips.cc/paper_files/paper/2024/hash/ee71a4b14ec26710b39ee6be113d7750-Abstract-Conference.html">Chain of Agents: Large Language Models Collaborating on Long-Context Tasks</a>) and enhanced agent capabilities (<a href="https://openreview.net/forum?id=3l2HnZXNou">Multi-Agent Coordination via Multi-Level Communication</a>), as well as the emerging capabilities of multi-model agents (<a href="https://proceedings.neurips.cc/paper_files/paper/2024/hash/f7ae4fe91d96f50abc2211f09b6a7e49-Abstract-Conference.html">FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement</a>).</p> <p>As LLMs get deployed in more and more applications, some of which are critical or contain sensitive information for end users, the understanding of the potential risks to these systems and how these can be mitigated is crucial, and research into these threats was very prominent at the NeurIPS conference. Works looking at jail-breaking of LLMs (<a href="https://proceedings.neurips.cc/paper_files/paper/2024/hash/439bf902de1807088d8b731ca20b0777-Abstract-Conference.html">Mission Impossible: A Statistical Perspective on Jailbreaking LLMs</a>), toxicity detection (<a href="https://openreview.net/forum?id=5a27EE8LxX">Toxicity Detection for Free</a>) and the emerging risks from agents (<a href="https://proceedings.neurips.cc/paper_files/paper/2024/hash/b6e9d6f4f3428cd5f3f9e9bbae2cab10-Abstract-Conference.html">Watch Out for Your Agents!</a>).</p> <p>Additionally, many discussions focused on the pressing challenges of fairness and bias in AI, as well as innovative efforts to address them. This included processes for de-biasing datasets (<a href="https://openreview.net/forum?id=ZVrrPNqHFw">A Simple Remedy for Dataset Bias via Self-Influence</a>), methods for estimating the fairness of algorithms (<a href="https://openreview.net/forum?id=ztwl4ubnXV&amp;referrer=%5Bthe%20profile%20of%20Zihao%20Fu%5D(%2Fprofile%3Fid%3D~Zihao_Fu1)">OxonFair: A Flexible Toolkit for Algorithmic Fairness</a>), and improvements on performance on under-represented groups in datasets (<a href="https://openreview.net/forum?id=vJLTcCBZVT">Improving Subgroup Robustness via Data Selection</a>).</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/635/0*viqopFaQeN2n5jRt.jpeg"/><figcaption>Poster sessions enabled researchers to share ideas and insights.</figcaption></figure> <p>All of these discussions were vital for us as scientists and engineers to ensure we keep these challenges at the front of our minds when using technology to develop services aimed at improving how we serve our customers.</p> <h3>The thriving AI community at NeurIPS</h3> <p>NeurIPS wasn’t just significant in terms of attendance; it also featured an impressive variety of events throughout the week and beyond. Participants could choose from engaging workshops and tutorials, as well as innovative projects presented by high school students. As well as this, there were affinity events and creative AI sessions throughout, and a huge number of community groups organised, meaning, despite the thousands of people there, there was an opportunity for everyone to connect with others who shared similar interests, making the experience inclusive and enriching despite the large turnout.</p> <p>The Exhibits Hall was alive with excitement, buzzing as vendors showcased their ground-breaking innovations and shared invaluable insights with conference presenters and attendees. Renowned tech giants like Google and Amazon drew large crowds, while dynamic startups such as Wayve exhibited their fresh ideas.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/619/0*iBw3B8Kvw7v4nuwG.jpeg"/><figcaption>Large tech companies and startups alike filled the Exhibition Hall.</figcaption></figure> <h3>Looking back and looking forward in AI</h3> <p>The past decade has been an incredible time for the field of machine learning and AI and the next ten years promises to be just as exciting. NeurIPS has a longstanding tradition of recognizing research that significantly impacts the field through its “Test of Time” award. This prestigious accolade honours the authors of seminal papers presented at the conference a decade ago. At the 2024 conference, two noteworthy works received this prize: the influential paper on <strong>“Generative Adversarial Networks”</strong> (GANs), which introduced a revolutionary framework for generative models, and <strong>“Sequence to Sequence Learning with Neural Networks”,</strong> which laid the groundwork for the advanced architectures that power today’s notable language models.</p> <p>A reflection of the former paper was presented by Ian Goodfellow and David Warde-Farley, while Ilya Sutskever, still one of the most well-known individuals in AI, presented reflections on the latter work and what he thought the future held for the field.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/608/0*pZ12u-BOi8c0N96s.jpeg"/><figcaption>Ilya Sutskever’s Test of Time talk reflected on the successes of the past decade and speculated where the field is going next.</figcaption></figure> <p>In his engaging talk, Sutskever highlighted that we are transitioning away from an era where advancements in models solely relied on scaling training compute and data. He pointed out the field is changing rapidly, with the focus shifting to agents, synthetic data, and test-time compute. This has been borne out in recent months, with the recent surge in research on agents and the release of reasoning models like OpenAI’s o3 model.</p> <h3>Arriving home full of ideas</h3> <p>Attending this event and seeing the cutting-edge of AI research, along with the individuals that have driven the field towards such success, was an amazing experience. Seeing NatWest Group sponsoring an event like this, alongside names like Duolingo, showed me how committed the bank is to being at the forefront of research.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/560/0*5tfxwPt8B_ituxM6.jpeg"/><figcaption>Conor Hamill and Raad Khraishi represented NatWest at the conference.</figcaption></figure> <p>We arrived home with loads of research ideas in our minds, eager to explore how the innovations we had seen could steer and be built on by <a href="https://www.natwestgroup.com/news-and-insights/latest-stories/ai-and-data/2024/aug/ai-research.html">the AI research happening across the bank</a> and with our university collaborators. Being able to see so much in such a short space of time kept us at the forefront of AI transformation and the support of senior data leaders in the bank meant that we were able to do this. AI is helping to accelerate change in financial services, and attending events like NeurIPS informs our research and equips us to deliver for our customers and stay on top of the cutting-edge developments that are shaping the future of banking.</p> <p>If you found this blog post interesting and would like to work on similar problems, we encourage you to take a look at our <a href="https://jobs.natwestgroup.com/pages/technology-digital-data?utm_source=natwestgroup.com&amp;utm_medium=referral&amp;utm_campaign=march_nwg_engineering_blog">available job openings</a>!</p> <p><em>The views and opinions expressed in this article are those of the author and do not necessarily represent the views of the NatWest Group.</em></p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=ab872d34ed01" width="1" height="1" alt=""/>&lt;hr&gt;&lt;p&gt;<a href="https://nwg.ai/natwest-group-ai-team-at-neurips-2024-ab872d34ed01">NatWest Group AI team at NeurIPS 2024</a> was originally published in <a href="https://nwg.ai">NatWest Group AI &amp; Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</p>]]></content><author><name></name></author></entry><entry><title type="html">Introducing our new AI &amp;amp; engineering blog: Insights from NatWest Group</title><link href="https://conor-hamill.github.io/blog/2025/introducing-our-new-ai-engineering-blog-insights-from-natwest-group/" rel="alternate" type="text/html" title="Introducing our new AI &amp;amp; engineering blog: Insights from NatWest Group"/><published>2025-02-28T09:59:25+00:00</published><updated>2025-02-28T09:59:25+00:00</updated><id>https://conor-hamill.github.io/blog/2025/introducing-our-new-ai--engineering-blog-insights-from-natwest-group</id><content type="html" xml:base="https://conor-hamill.github.io/blog/2025/introducing-our-new-ai-engineering-blog-insights-from-natwest-group/"><![CDATA[<p><em>By Greig Cowan (</em><a href="https://www.linkedin.com/in/greigcowan/"><em>Head of AI &amp; Data Science Innovation</em></a><em>)</em></p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Dy6-a4Ei2JidOkdwzZvxZA.png"/><figcaption>Welcome to our blog</figcaption></figure> <p>Innovation isn’t just about adopting new technologies — it’s about building resilient, scalable, and ethical solutions that enhance customer and colleague experiences and drive operational excellence.</p> <p>That’s why we’re launching this blog: a dedicated space where we share insights, lessons, and real-world applications of AI and engineering in the context of financial services. Whether you’re an AI practitioner, software engineer, data scientist, delivery manager, or simply interested in the role technology is playing to help shape the future of finance, this blog will offer insights from the teams who are driving tech change across our bank.</p> <h3>What you can expect</h3> <h4>AI in banking</h4> <p>AI is everywhere but applying it effectively in a highly regulated industry like banking requires careful design, rigorous validation, and strong governance. We’ll discuss real-world use cases — from risk modelling to AI-powered customer interactions and pricing optimisation.</p> <h4>Engineering at scale</h4> <p>Banks operate complex technology ecosystems. We’ll share insights into building and maintaining scalable, resilient, and secure systems that power millions of transactions and interactions every day. Expect articles on cloud adoption, data engineering, software architecture, and site reliability engineering.</p> <h4>Data &amp; analytics: Turning insights into action</h4> <p>From developing machine learning models to creating real-time analytics dashboards, we’ll cover how our teams transform raw data into actionable insights that help drive better decision-making.</p> <h4>Security &amp; compliance in AI and engineering</h4> <p>In financial services, innovation must go hand-in-hand with responsibility. We’ll explore best practices for building systems that are explainable, fair, and compliant with evolving regulations — ensuring trust and security at every step.</p> <h4>Careers &amp; ways of working</h4> <p>Technology is only as good as the people who build it. We’ll share stories from our engineering and AI teams, insights into how we work, our R&amp;D projects, and advice for professionals looking to build a career in AI and financial technology.</p> <h3>Why this blog?</h3> <p>We’re building this blog not just to showcase our work, but to contribute to the wider AI and engineering community. As technology leaders, we believe in transparency, collaboration, and continuous learning. Whether it’s lessons from our successes or challenges we’ve faced, we want to foster conversations that push the boundaries of what’s possible in financial technology.</p> <p><em>The views and opinions expressed in this article are those of the author and do not necessarily represent the views of the NatWest Group.</em></p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=c265ceb07db4" width="1" height="1" alt=""/>&lt;hr&gt;&lt;p&gt;<a href="https://nwg.ai/introducing-our-new-ai-engineering-blog-insights-from-natwest-group-c265ceb07db4">Introducing our new AI &amp; engineering blog: Insights from NatWest Group</a> was originally published in <a href="https://nwg.ai">NatWest Group AI &amp; Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</p>]]></content><author><name></name></author></entry><entry><title type="html">My 2024 in reading</title><link href="https://conor-hamill.github.io/blog/2024/my-2024-in-reading/" rel="alternate" type="text/html" title="My 2024 in reading"/><published>2024-12-29T12:30:00+00:00</published><updated>2024-12-29T12:30:00+00:00</updated><id>https://conor-hamill.github.io/blog/2024/my-2024-in-reading</id><content type="html" xml:base="https://conor-hamill.github.io/blog/2024/my-2024-in-reading/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/reading-unsplash-480.webp 480w,/assets/img/reading-unsplash-800.webp 800w,/assets/img/reading-unsplash-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/reading-unsplash.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/reading-coffee-unsplash-480.webp 480w,/assets/img/reading-coffee-unsplash-800.webp 800w,/assets/img/reading-coffee-unsplash-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/reading-coffee-unsplash.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Images taken from <a href="https://unsplash.com">unsplash.com</a>. </div> <h1 id="introduction">Introduction</h1> <p>As 2024 wraps up and I do my best to recover from whatever cold/mild flu is trying to keep me from New Year’s celebrations, I thought it might be a good moment to write up my highlights in things I read this year, across novels, non-fiction, and blogs. I was fortunate enough to hit my Goodreads challenge of 15 books, with a bonus one snuck in as my immune system confined me to the indoors, with a good spread across fiction and non-fiction!</p> <h1 id="fantasy-and-sci-fi">Fantasy and sci-fi</h1> <ul> <li><em>Lyra’s Oxford</em>, Philip Pullman</li> <li><em>Once Upon a Time in the North</em>, Philip Pullman</li> <li><em>A Day of Fallen Night</em>, Samantha Shannon</li> </ul> <p>I started off this year reading the novella’s based in Philip Pullman’s world of <em>His Dark Materials</em> and <em>The Book of Dust</em>, <em>Once Upon a Time in the North</em> and <em>Lyra’s Oxford</em>. I’ve always loved this world but never got round to reading these short books, which served as a nice holdover over until the third and final book in the trilogy gets released, <a href="https://x.com/PhilipPullman/status/1824487662528393639">which I think we can be pretty confident of having a release date next year</a>! Lyra’s Oxford depicts her life in Oxford after the events of <em>The Amber Spyglass</em> in a short story that has some links into <em>The Secret Commonwealth</em>. It expands on the Oxford that exists in the world of <em>His Dark Materials</em>, along with some maps and other documents that flesh out the world a bit more. <em>Once Upon a Time in the North</em> is a short story describing the first meeting of Iorek and Lee Scoresby, two fan favourite characters from <em>His Dark Materials</em>. I liked both of these novellas, but wouldn’t consider either of them mandatory reading for the series as a whole, although <em>Lyra’s Oxford</em> does give a nice introduction to some characters we encounter again in The Secret Commonwealth, and returning to Philip Pullman’s world is always a treat.</p> <p><em>A Day of Fallen Night</em> by Samantha Shannon is a prequel to 2019’s <em>The Priory of the Orange Tree</em>, which introduced her fantasy world of diverse cultures in a “feminist retelling of Saint George and the Dragon”. While I’m probably not the exact target audience for these books, like the previous title, <em>A Day of Fallen Night</em> was a great read. Some of the issues in pacing and characterisation have definitely improved since the last book, and I think this will only get better as Shannon re-visits the rich fantasy world of <em>Roots of Chaos</em> that she’s created.</p> <h1 id="horror">Horror</h1> <ul> <li><em>Pet Sematary</em>, Stephen King</li> </ul> <p>In terms of horror books, I had a fairly limited year, but <em>Pet Sematary</em> was a real stand out among all the books I read. This was a fantastic read and I can see why it’s always highlighted as one of King’s best, so I would definitely recommend to any horror fans or anyone who has enjoyed his other works. This book is definitely up there with some of King’s most distributing, and he recently said himself <a href="https://ew.com/movies/2019/03/29/pet-sematary-stephen-king-interview/">“This is awful. This is really f—ing terrible.”</a>. While I think <em>The Shining</em> is still his scariest book, this definitely stands out as his most horrifying.</p> <h1 id="crime-and-espionage">Crime and espionage</h1> <ul> <li><em>Thirteen</em>, Steve Cavanagh</li> <li><em>Absolute Friends</em>, John le Carre</li> <li><em>Strip Jack</em>, Ian Rankin</li> </ul> <p><em>Thirteen</em> by Steve Cavanagh came with the recommendation of Chris Dillon, and it did not disappoint. A really great thriller and I want to make sure I try more of Cavanagh’s stuff in 2025.</p> <p><em>Absolute Friends</em> by John le Carre was a kind lend from Thomas Lee, who is responsible for introducing me to the works of le Carre. This is definitely one of le Carre’s lesser known novels, covering a friendship across many decades of the 20th century across divided Europe, and feels like one of le Carre’s works that might have a hint of self-insertion in it. While the ending is a little bit out of left field, I would recommend this as one for fans of slow burn espionage to pick up.</p> <p>I finished up <em>Strip Jack</em> recently, and it’s a great entry to the Rebus series, with a tight and focussed story. As one of the earlier Rebus novels, characters like Siobhan and Cafferty are present, but I found I didn’t miss them that much. Would recommend to any Rebus or Scottish crime fans.</p> <h1 id="other-fiction">Other fiction</h1> <ul> <li><em>Watership Down</em>, Richard Adams</li> <li><em>Go Set a Watchman</em>, Harper Lee</li> <li><em>Close to Home</em>, Michael Magee</li> <li><em>Foster</em>, Claire Keegan</li> </ul> <p>With only vague memories of watching the TV show as a child, I found <em>Watership Down</em> a really enjoyable book, that lived up to its reputation of being filled with adventure, great characters, and conflict you wouldn’t expect in a book about rabbits. I was amazed at the depth of the rabbit lore and how well the story stands up, but I’m not sure who I would recommend this to - a bit too horrifying for young children, but maybe not what a lot of adults are looking for, but doesn’t really fit into young adult fiction? Anyway, it doesn’t matter - a great book that remains rightfully considered as a classic.</p> <p>Overall, I think I enjoyed <em>Go Set a Watchman</em> a lot more than the near-universal negative response it got when it was published. It’s definitely a strange book, especially given how established and influential its predecessor is. For me, it seemed to meander quite a bit, then jump to it’s conclusion all of a sudden. It nearly felt like there was another act, or another entire novel, that could have been there to describe how Scout arrived at the final state of her relationship with father. It really does feel like a shame that this is what we got from the Lee estate, but does not diminish any significance of the first book.</p> <p>Close to Home by Michael Magee was a standout novel of the year for me. This semi-autobiographical work based in modern Belfast tackles dealing with the past, finding personal identity, and the working class in Belfast.</p> <p><em>Foster</em> by Claire Keegan was a wonderfully written novella, depicting life in rural Ireland, and I definitely want to read more of her works in 2025.</p> <h1 id="non-fiction">Non-fiction</h1> <ul> <li><em>Monsters</em>, Claire Dederer</li> <li><em>You Don’t Have to Be Mad to Work Here</em>, Benji Waterhouse</li> <li><em>Not the End of the World</em>, Hannah Ritchie</li> <li><em>GCHQ</em>, Richard J. Aldrich</li> <li><em>The Future of Geography</em>, Tim Marshall</li> </ul> <p><em>You Don’t Have to Be Mad to Work Here</em> by Dr. Benji Waterhouse was an enlightening and funny dive into the world of psychiatry, as well as Benji’s personal life. This book had a fantastic opening dedication and I’d hugely recommend.</p> <p><em>Not the End of the World</em> by Hannah Ritchie was another great non-fiction reads of this year, with an optimistic outlook on what we can do to make our planet sustainable. Would give this a wholehearted recommendation for anyone. We were also lucky enough to see Hannah Ritchie present this book at the wonderful <a href="https://www.toppingbooks.co.uk/">Topping Books</a> in Edinburgh, where she was able to answer any and all questions about her research on the spot! She also has a great substack, <a href="https://www.sustainabilitybynumbers.com/?utm_source=substack&amp;utm_medium=web&amp;utm_campaign=substack_profile">Sustainability by Numbers</a>, where she continues to share about the climate and data.</p> <p><em>Monsters</em> by Claire Dederer was a good read that starts off trying to answer the question “how can we enjoy great art made by terrible people?”, a question that has only become more pertinent as the number of artists found guilty of various crimes rises. This book diverted into a more autobiographical work as it went along, and while I’m not sure if it fully answered the question it set out to answer, I enjoyed the analysis of the history of people who have created notable works. The history of the UK’s intelligence, security and cyber agency is covered in <em>GCHQ</em> by Richard J. Aldrich. I learnt a lot about the organisation and its role in the Cold War, with the final 100 pages being the most interesting as GCHQ finds its place in the modern age, but some of the sections were quite dense and weighed down by the amount of information in them.</p> <p><em>The Future of Geography</em> by Tim Marshall was another great work by the author of <em>Prisoners of Geography</em>. The history of the space race during the Cold War and the competition for space in the 21st century will change our world were great reads and I would recommend this to any geography, politics, or space nerd.</p> <h1 id="substacksblogs">Substacks/blogs</h1> <p>This year I got a bit more into Substack, which has become a pleasant spot on the internet for people to write about their niche interests, with authors having control over what content is paid for and readers not being swamped by adverts.</p> <ul> <li><a href="https://www.natesilver.net/">The Silver Bulletin</a>, by Nate Silver <ul> <li>This blog covers analysis on elections, media, and sports and was a great resource for interpreting data during the 2024 US election.</li> </ul> </li> <li><a href="https://verynormal.substack.com/">Very Normal</a> by Christian Pascual <ul> <li>This substack focuses on an approachable manner to teaching concepts statistics, and Christian also has a great <a href="https://www.youtube.com/@very-normal">YouTube channel</a>.</li> </ul> </li> <li><a href="https://www.sustainabilitybynumbers.com/">Sustainability by Numbers</a>, by Hannah Ritchie <ul> <li>I’ve mentioned this above, but this substack focuses on applying data to understand the challenges facing our climate, from the author of <em>Not the End of the World</em>.</li> </ul> </li> <li><a href="https://edinburghminute.substack.com/">The Edinburgh Minute</a>, by Michael MacLeod <ul> <li>This doesn’t quite fit among the other substacks, but for local news in Edinburgh, this daily newsletter can’t be beaten. Highlight recommend.</li> </ul> </li> </ul> <h1 id="some-wonderful-bookshops">Some wonderful bookshops</h1> <p>I also wanted to highlight some of the great bookshops I’ve been to in Edinburgh, Belfast, and Nashville this year, which have fuelled my reading.</p> <ul> <li><a href="https://www.toppingbooks.co.uk/">Topping and Company, Edinburgh</a></li> <li><a href="https://www.theportobellobookshop.com/">The Portobello Bookshop, Edinburgh</a></li> <li><a href="https://rarebirdsbooks.com/pages/visit-us">Rare birds books, Edinburgh</a></li> <li><a href="https://www.parnassusbooks.net/">Parnassus Books, Nashville</a></li> <li><a href="https://noalibis.com/">No Alibis Bookstore, Belfast</a></li> </ul> <p>Here’s to another great year of reading in 2025!</p>]]></content><author><name></name></author><category term="posts"/><category term="books"/><summary type="html"><![CDATA[Some reflections on the books I read this year]]></summary></entry><entry><title type="html">So you want to get into data science?</title><link href="https://conor-hamill.github.io/blog/2024/getting-into-data-science/" rel="alternate" type="text/html" title="So you want to get into data science?"/><published>2024-09-08T17:30:00+00:00</published><updated>2024-09-08T17:30:00+00:00</updated><id>https://conor-hamill.github.io/blog/2024/getting-into-data-science</id><content type="html" xml:base="https://conor-hamill.github.io/blog/2024/getting-into-data-science/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/hike-unsplash-image-480.webp 480w,/assets/img/hike-unsplash-image-800.webp 800w,/assets/img/hike-unsplash-image-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/hike-unsplash-image.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dashboard-unsplash-image-480.webp 480w,/assets/img/dashboard-unsplash-image-800.webp 800w,/assets/img/dashboard-unsplash-image-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/dashboard-unsplash-image.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Images taken from <a href="https://unsplash.com">unsplash.com </a>. </div> <h2 id="introduction">Introduction</h2> <p>As with all the content on this website and in my blog posts, the opinions expressed here are my own and not those of my employer. More and more often recently, I’ve been asked by students and others “So, what do I need to do to get a job as a data scientist?”. I’ve realised, although I have lots of thoughts on this, the answers I’ve been giving have been rather rambling and unstructured, with more points than any person can reasonably hold on to while talking to me at a careers fair. So I decided to put these thoughts into this short post to bring these notions together in one place. This article will naturally be biased towards someone with a degree in natural sciences (e.g. physics), who has had some experience in programming and statistical analysis, and also inevitably biased towards my personal opinions and recollections.</p> <h2 id="do-you-really-want-to-get-into-data-science">Do you really want to get into data science?</h2> <p>As always before embarking on anything new which will take up a lot of your time, you should yourself two start with two key questions:</p> <ol> <li>Why do I want to do this?</li> <li>Do I really know what I’m getting into?</li> </ol> <p>I highlight these two questions because putting a lot of effort into breaking into data science before realising that it isn’t what you want to do, or it isn’t really what you thought it would be, would be less than ideal. Data science is often not as glamorous as it is depicted, although the perception is now a bit more grounded than it was in the days of “the sexiest job of the 21st century”. As a data scientist, you are required to undertake several different roles at once, stay up to date with a technology landscape that changes extremely quickly, work with requirements that are often unclear and shifting, and, most crucially, you are required to make an impact on the business; to senior management you are a new investment, and they want a return on that investment. Many technology and software-based roles also have these aspects to various degrees, but these are all distinct realities of being a data scientist. Part of this comes from data scientist roles looking different across different organisations and how rapid developments in the world of data and AI has led to high expectations from business leaders. However, my personal opinion is that if you want a job that uses programming and statistical modelling to solve problems, and you want to convince business leaders you’ve solved those problems, you could do far worse than a role as a data scientist.</p> <h2 id="roles-in-data-beyond-data-science">Roles in data beyond data science</h2> <p>A point sometimes neglected is that the volume and variety of data roles beyond that of data scientist are growing year-on-year. As data science practices mature in businesses, the range of professions is increasing, with roles that are more defined than before. This trend seems to closely follow business consensus that you need a much more sophisticated data strategy to really transform a business than just training a model. Some roles, especially data engineers and machine learning engineers, are more sought after than data scientists, and will commonly pay better. There are also roles that require a different range of skills and still provide substantial business value. For example, data analysts can give great insights from data and clearly inform business decision-making, without the need for python and complex algorithms. Additionally, it’s becoming more commonplace for individuals to pivot from related data roles into data science. In short, it will be well worth you’re time exploring which one of these roles you think might best fit your skill set and what you enjoy doing.</p> <h2 id="how-would-i-go-about-learning-data-science-again">How would I go about learning data science again</h2> <p>So, you’ve looked the other roles and decided it’s for you; what do you need to learn and how do you sell yourself? If I was to go back in time and try again to move into data science again, I’d would still follow the same high-level path I took before, with some changes on what I spent the most time on:</p> <ol> <li>Learn the required skills</li> <li>Complete some personal/in work projects to exhibit those skills</li> <li>Advertise those projects to prospective employers</li> </ol> <p>I’ll go through each of these in order in some more detail below.</p> <h3 id="learning-the-skills-you-need">Learning the skills you need</h3> <p>There are a wide range of skills that data scientists need to have, some of which you need to excel at, while knowing the basics of others can suffice. Knowing which of these is which can be tricky.</p> <p>Before picking which resources you want to use to learn, consider what medium you best learn through. I find personally I learn best through textbooks and visual media, but collections of videos seem to be very effective for others. Additionally, be wary of falling into the trap of using bite-sized pieces of knowledge to give yourself the illusion of learning, when you’re really just skimming the surface of the required knowledge and missing deeper connections. Andrej Karpathy described this very well in this <a href="https://x.com/karpathy/status/1756380066580455557?lang=en">recent post on X/Twitter</a>, from which I highlight a paragraph that I find quite impactful:</p> <blockquote> <p>So for those who actually want to learn. Unless you are trying to learn something narrow and specific, close those tabs with quick blog posts. Close those tabs of “Learn XYZ in 10 minutes”. Consider the opportunity cost of snacking and seek the meal - the textbooks, docs, papers, manuals, longform. Allocate a 4 hour window. Don’t just read, take notes, re-read, re-phrase, process, manipulate, learn.</p> </blockquote> <p>     Andrej Karpathy, <a href="https://x.com/karpathy/status/1756380066580455557?lang=en">Twitter/X</a></p> <p>Below I describe roughly the order I would undertake learning, assuming a prior degree in some sort of science. Many of these resources are described in my <a href="/data_science_resources/">page on data science resources</a>.</p> <ul> <li>Learn software development: <ul> <li>with <a href="https://missing.csail.mit.edu/">the missing semester course from MIT</a>. <ul> <li>this might feel like a dry one to start off with, but since this is probably the most fundamental skill here and all others rely on it, it is a good place to start. Being comfortable with you terminal and being able to collaborate using Git will make future learnings and your eventual job much easier.</li> </ul> </li> </ul> </li> <li>Learn python: <ul> <li>I don’t have an exact python course I would recommend and given there are many different levels you may be starting at, I would steer you towards the <a href="https://realpython.com/learning-paths/">choice of python learning paths on Real Python</a>.</li> <li>The main python website <a href="https://www.python.org/about/gettingstarted/">python.org</a> has also indexed many useful resources <ul> <li>Out of all the skills here, python is the one you probably want to put the most time into being good at, because it will be the end product you will be producing a lot of the time.</li> </ul> </li> </ul> </li> <li>Learn statistical modelling: <ul> <li>The book “An Introduction to Statistical Learning” is available with examples in R or Python <a href="https://www.statlearning.com/">here</a>. <ul> <li>I’ve found this book to cover the level of detail needed to understand modelling as a data scientist in a very digestible way.</li> </ul> </li> </ul> </li> <li>Learn how to do a machine learning project: <ul> <li>This point has a lot of similarities with the above, but I think this one begins the focus on the python packages used more</li> <li>Andrew Ng’s <a href="https://www.deeplearning.ai/courses/machine-learning-specialization/">machine learning specialisation</a> on Coursera remains a classic for a reason, although pytorch has established itself over Tensorflow as the python deep learning framework of choice</li> <li>For a book alternative, I would recommend <a href="https://sebastianraschka.com/blog/2022/ml-pytorch-book.html">“Machine Learning with PyTorch and Scikit-Learn”</a></li> </ul> </li> <li>Learn (some) cloud computing: <ul> <li>How much you need to know will vary role by role, but understanding the fundamentals is good.</li> <li>I don’t have a stand-out recommendation for learning cloud computing, but have had a good experience learning with Udemy’s courses on AWS in the past. This <a href="https://www.udemy.com/course/introduction-to-cloud-computing-on-amazon-aws-for-beginners/">one may be a good introduction</a> for those new to AWS or cloud computing.</li> </ul> </li> </ul> <p>After (or maybe while) you have learnt the above skills, you can begin to undertake some personal projects.</p> <h3 id="doing-some-personal-projects">Doing some personal projects</h3> <p>You need to show that you can use your skills to solve problems and explain why you’ve made the choices that you have. Picking a good personal project can be tricky; you want something that is complex enough to challenge yourself, but not something that isn’t fundamentally unfixable. Remember that training a good machine learning model is only one of the components of providing a business-ready solution - if you are able to implement an end-to-end solution, possibly deploying in the cloud, that can be very impressive (but do remain vigilant of AWS costs piling up rapidly!).</p> <p>Do something that is either relevant to an industry you’re interested in or that you’re personally interested in. This makes it more likely the problem and solution will be more relevant to roles you’re looking for and more interesting all round. Alternatively, if you can apply some data science to your current role, that is an excellent way to show you can take initiative and solve problems.</p> <h3 id="advertise-these-projects-to-potential-employers">Advertise these projects to potential employers</h3> <p>Finally, you want to make sure that potential recruiters will see these projects, and you can set yourself apart from other applicants. Put the code that you have developed in a public GitHub repository and make sure it has a story behind it - maybe you want to write a blog about it, or make a really interesting readme for the project, or find some way to host it online for others to use! Whatever way you decide to advertise it, make sure it clearly shows how you’ve solved your problem and links to your code. Additionally, do spend time tuning your CV to sell yourself and make sure it’s specific to whatever job you are applying to.</p> <h2 id="conclusions">Conclusions</h2> <p>That wraps up some pointers for how I would go about trying to get into data science if I had to again. Bear in mind this guide is very much not end-to-end and many of the soft skills that are essential for a data science are not given the time they are due in this post. Some resources below include alternative opinions that might be useful.</p> <h2 id="resources">Resources</h2> <ul> <li><a href="https://www.reddit.com/r/datascience/comments/qph4tx/how_to_get_a_job_in_data_science_a_semiharsh_qa/">How to get a job in data science - a semi-harsh Q/A guide</a> - many of the sentiments in this article are echoed in this post from u/save_the_pandas_bears, albeit in some stronger tones</li> <li><a href="https://www.datacamp.com/blog/how-to-become-a-data-scientist">How to become a Data Scientist in 2024 - Datacamp</a></li> <li><a href="https://shecancode.io/blog/can-i-get-a-data-science-job-with-no-prior-experience/">“Can I get a data science job with no experience?” - SheCanCode</a></li> </ul>]]></content><author><name></name></author><category term="posts"/><category term="data-science"/><summary type="html"><![CDATA[Some advice on how I would go about moving into data science if I had to do it again]]></summary></entry><entry><title type="html">What I would tell myself at the start of my PhD</title><link href="https://conor-hamill.github.io/blog/2024/what-I-would-tell-myself-phd/" rel="alternate" type="text/html" title="What I would tell myself at the start of my PhD"/><published>2024-06-18T17:30:00+00:00</published><updated>2024-06-18T17:30:00+00:00</updated><id>https://conor-hamill.github.io/blog/2024/what-I-would-tell-myself-phd</id><content type="html" xml:base="https://conor-hamill.github.io/blog/2024/what-I-would-tell-myself-phd/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/nebula-image-480.webp 480w,/assets/img/nebula-image-800.webp 800w,/assets/img/nebula-image-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/nebula-image.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/books-image-480.webp 480w,/assets/img/books-image-800.webp 800w,/assets/img/books-image-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/books-image.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Images taken from <a href="https://unsplash.com">unsplash.com</a>. </div> <h2 id="introduction">Introduction</h2> <p>Completing my PhD in nuclear astrophysics in 2021 was the end of an experience filled with both immense challenges and rewarding experiences. After this, I transitioned from academia to industry and have worked for three years as a data scientist in financial services. I really enjoyed my PhD (despite the start of it being quite challenging and the pandemic making the end a bit of a damp squib) and it led to a very satisfying job in a team I really enjoy being part of, but there are lots of things I wish I had said to myself or had done differently during my PhD. One of the perennial problems in academia is that the knowledge and experiences of people in research groups are often lost as they move to different roles in different institutions. This happens very commonly with departing PhD students; the people who were once a major component of a research group are now only remembered by their names on the side of old theses on an office shelf. Given this, and since I’ve been away from my PhD long enough to see the world outside academia and reflect on things, compiling advice to give my past self seemed like a good activity.</p> <p>I started my PhD in nuclear astrophysics at the University of Edinburgh after completing my integrated master’s at Queen’s University Belfast, in a different sub-field to that of my master’s project. After submitting my thesis I got a job in a large retail bank as a data scientist, where I still work. The thoughts in this article will be specific to these experiences, and might not be directly applicable to those in other fields, programmes, or who continued their academic career, but hopefully some parts will be of use to anyone undertaking a PhD. This blog post contains the advice I would give to myself at the start of my PhD, to provide a little bit of help navigating the highs and lows. Whether you’re just starting out or knee-deep in your research, I hope you find something here that is of some use, or at least resonates with you.</p> <h2 id="get-organised-and-learn-the-skills-you-will-need-from-the-start">Get organised and learn the skills you will need from the start</h2> <h4 id="stay-organised">Stay Organised</h4> <p>Taking steps to be organised from the get go will serve you well as you establish yourself as a reliable department member and reduce the cognitive load of juggling things in your mind. The week-to-week rhythm of a PhD programme is much less structured than undergrad programmes, so keeping track of a wide range of events may be somewhat new. Whether with a physical diary or a virtual calendar, use whatever tools you need to keep yourself accountable and remember meetings, deadlines, and appointments.</p> <h4 id="learn-to-code-efficiently">Learn to Code Efficiently</h4> <p>Something that I think is chronically underrated in most PhD programmes is learning how to use your terminal and write high-quality code. A large component of the day-to-day work you will be doing will be coding and will likely be one of the most important skills for future employers, so learning to do this well early on and continuing to actively improve during your programme will serve you well. There are many many courses out there for learning your terminal and every programming language, but one course I think that should be mandatory is the <a href="https://missing.csail.mit.edu/">missing semester course from MIT/</a>; this course covers using the command line, using your editor efficiently, and gives a good overview of how you can make your workflow more efficient and your life easier. My undergraduate programme covered a wide range of physics topics very well, but a lot of what I learnt about the command line and the surrounding ecosystem came from outside my course, so this would have really helped early in my PhD. Something essential that is covered in that course is version control using Git, a tool that is ubiquitous across any role that involves programming and something that will make controlling the code (and manuscripts) you write a lot easier. This can be skipped in undergraduate courses but is a skill everyone wishes they had learnt earlier.</p> <h4 id="choose-the-best-tools-for-the-job">Choose the best tools for the job</h4> <p>You will also need to choose what IDE and reference manager you will be using. Spending a bit of time choosing which of these you prefer can be worth it, given how much time you will be spending using them. For IDEs, <a href="https://www.jetbrains.com/pycharm/">pycharm</a> or <a href="https://code.visualstudio.com/">VSCode</a> are popular choices for a reason, and the reference manager Zotero allows article organisation, sharing across devices, and automatic extraction of information, making it a useful tool.</p> <h4 id="leverage-the-past-experiences-of-others">Leverage the past experiences of others</h4> <p>Do also ask older students (who will be a great source of information) what tools they’ve found to be useful and what resources they’ve found useful for learning programming - people who have recently walked the path you’re on will know best.</p> <h2 id="dont-compare-yourself-against-other-people">Don’t compare yourself against other people</h2> <p>Comparison is always the thief of joy, and never more so than during a PhD. In one sentence: do not compare your progress, skills, or achievements to others in your group or anyone else doing a PhD. This will simply make you unhappy as you form a habit of picking apart everything that hasn’t gone amazingly. In addition, it is an objectively terrible metric to measure your progress against. There are several reasons for why this simply isn’t a good measure of how you’re progressing, but what’s key to remember is that the structure from the undergrad degree where everyone takes the same lectures and exams at the same time is no longer there. First, your colleagues will have come from different universities, which may have focussed more or less on skills like programming, or may have specialised in your particular PhD field, meaning everyone is at a different starting point. Second, everyone’s project is different - some might be more theoretical, some might be part of a larger collaboration, while some may focus on one specific device; everyone’s PhD project is unique. Thirdly, there are simply some things that will be outside your control. This will include experiment scheduling, the work of collaborators, and academic politics.</p> <h3 id="focus-on-your-own-path">Focus on your own path</h3> <p>Concentrate on the things that you can control day-to-day and don’t feel that your colleague’s breakthrough, publication, or talk is a sign you’re falling behind or that you’re not cut out for things. Celebrate each and every milestone, as minor as they may be, and, whatever pace you’re moving at, give yourself credit for every step you move forward.</p> <h2 id="treat-it-like-a-job">Treat it like a job</h2> <p>Doing a PhD is full of contradictions: you’re still a student, but getting paid; you have lots of work to be doing, but often no defined working hours; you’re still learning, but considered an expert in your field. While you might not ever have flexibility like this again in your career, treating your PhD like a job with a regular 9-5 job, with clearly defined boundaries between work and time off, is likely the best to do for your productivity and well being. Waking up at the same every day will help you control your energy levels while giving you time to turn off from work. Keeping the work-life boundary is also important and going into your office and not checking emails when at home will be a key part of this. Finally, you’ll still have peers who want to head out throughout the week, so it’s up to you to enjoy yourself while balancing where your energy goes.</p> <h2 id="engage-with-your-department-and-community-effectively">Engage with your department and community effectively</h2> <h3 id="interact-with-everyone">Interact with everyone</h3> <p>There will likely be no other point in your life that you’re in an environment with such smart and hard-working people who are the top experts in your field. Get to know them and their experiences and learn everything you can from them. Part of this is going into the office, chatting during coffee breaks and lunch and being genuinely interested in their research. Additionally, if there are internal presentations or reading groups, do go to those, make your own contributions, and if you don’t have these, make a proposal to senior members of your department about what they could look like and why you should have them. Older students are great sources of information and being able to passively pick up advice from them is invaluable, but this will often only happen if you see them in-person.</p> <h3 id="keep-communication-with-your-supervisor-strong">Keep communication with your supervisor strong</h3> <p>Supervisors have vastly different rhythms for communicating with their students and especially for those that are hands off, flying under the radar can easily happen. My suggestion to avoid this is to communicate regularly and in-detail with them so anything that’s a problem is highlighted as early as possible, and they have a clear view of how your research is going. One way of doing this might be a weekly email that describes what you did that week, what you found out, what you found challenging, and anything that you think is an issue. As well as making sure your supervisor is abreast of everything happening in your research, it means that you will get the satisfaction of seeing your work progress week-to-week and have a record of everything you’ve achieved.</p> <h2 id="keep-non-phd-interests">Keep non-PhD interests</h2> <p>Like the muscles in your body, your brain needs to relax every so often or it will begin to be strained. Making time for your non-PhD interests from week-to-week is a great way of doing this and not letting your PhD work consume your thoughts and identity. Additionally, make sure part of this non-PhD time is dedicated to physical activity, be it team sports, the gym, or walking.</p> <h2 id="people-will-not-understand-what-youre-doing-or-why-youre-doing-it">People will not understand what you’re doing or why you’re doing it</h2> <p>You will likely get a wide variety of reactions whenever you tell people that you’re doing a PhD. Some will proclaim you a genius for starting a programme (which you should still be proud of), while some will be suggesting you’re putting off the world of work, or lying in bed all day. Both ends of this spectrum of this reaction can exacerbate imposter syndrome - it can be common to not feel as smart as others might describe you and you also might feel that you indeed haven’t made much progress in things. It can be frustrating and lonely that others don’t understand the nature of the challenges a PhD entails, and describing these challenges can be difficult in itself. But the truth is that very few people will understand the nature of your work, or your exact experience going through it, as, by its very nature, you are covering uncharted territory. So learn to shrug off the sceptics and accept the faith that people have in your ability, and learn your one sentence lay-person description of your work that doesn’t exact capture what you’re doing, but is close enough and sounds a little bit interesting: “I’m doing experiments to help find out where all the elements in our Galaxy come from”.</p> <h2 id="nailing-the-landing-is-difficult-if-not-impossible">Nailing the landing is difficult, if not impossible</h2> <h3 id="plan-for-the-future">Plan for the future</h3> <p>While it may seem like a lifetime away whenever you begin your programme, your PhD studies will come to an end at some point. The end of the PhD will quite often require some multi-tasking: wrapping up final data analysis, applying for new roles, and of course, writing your thesis. This is inevitably a difficult time, but there are some steps you can take to try to make this time as straightforward as possible.</p> <h3 id="career-preparation">Career preparation</h3> <p>The foremost tip I would have is to give some thought to next career steps in your career early on in your PhD, possibly as early as your second year. Don’t worry if you don’t know immediately what it is you want to and it’s perfectly fine to change your mind, but the earlier you think about this, the earlier you can take steps to make the end of your PhD easier. Take an industry placement if you can: this will give you exposure to the world outside academia, providing you with new contacts and skills, and something to differentiate your CV.</p> <h3 id="coding-skills-for-industry">Coding skills for industry</h3> <p>For anyone planning to get a job in industry after their PhD, the one bit of definite advice I would give would be: <strong>learn to code and learn to code well</strong>. This will be very likely what you will be doing in industry, so the sooner you get better at it, the sooner you can market your skills well. Also think about the programming language that you’ve used in your PhD; if it is a proprietary language or one that’s quite niche to academia, consider investing time in learning a more common language, or advertising the general programming skills you’ve acquired (object-oriented programming, multi-core programming). Also remember that recruiters and employers will often not speak the same language as you - having a well-cited paper is impressive and a strong marker of success in academia, but describing the more practical results of code you wrote or actions you took will land more strongly with employers. Also remember that you have acquired a lot of skills in your PhD, by working in a team, presenting and justifying results, and managing your own time, but making sure these are communicated in a way that industry can interpret them is essential to making an impact in the job market.</p> <h2 id="writing-your-thesis">Writing your thesis</h2> <p>I also need to echo what many more have said on having perfection as the enemy of done when it comes to writing a PhD thesis. It is natural to feel attached to the quality of this book you have written, after all it is a culmination of many years of work and learning. However, it is worth bearing in mind that it is a means to an end: a document to show your assessors that you have done novel research and are deserving of your degree. As the saying goes, “There is no such thing as a perfect thesis, only a done thesis”. In addition, the writing of your thesis will take at least twice as long as you think, no matter how you go about it, which is something to bear in mind whenever you are planning when to start writing and when to tell an employer you can start.</p> <h2 id="leaving-your-programme-is-not-the-end-of-the-world">Leaving your programme is not the end of the world</h2> <p>Finally, I want to say that if you do decide that you do leave your PhD programme for whatever reason, you are no way in the slightest a failure and this does not define your worth or success. The truth is, in general, no one cares a huge deal if you have a PhD or not. When you start a job, you are known by your job title, not the letters before or after your name. Leaving a PhD can often be the correct decision; in the end we have to weigh up the rewards and efforts of every endeavour in life, and if the scales tilt in the negative direction, then it simply isn’t worth persisting. If you feel like people will be disappointed in you for quitting, then doing a PhD to impress them wasn’t the correct choice in the first place. For an employment perspective, you still have each and every one of the skills you developed over the course of your PhD. Having the final degree certificate doesn’t make a difference in how well you undertake your next role.</p> <h2 id="conclusion">Conclusion</h2> <p>These were some of my thoughts I had when reflecting back on my PhD experience. Hopefully they ring true for some others and are useful to those starting or mid-way through their PhD journeys. Overall, remember that everyone’s PhD journey is unique and not comparable to others, make sure you have a life and interests outside your PhD, think (but don’t worry) about the future, learn to code, and accept your thesis may not be the immaculate masterpiece you set out to create (and that’s perfectly fine).</p>]]></content><author><name></name></author><category term="posts"/><category term="phd"/><summary type="html"><![CDATA[Some reflections and advice I would give myself starting a PhD]]></summary></entry><entry><title type="html">Visualisation libraries in python for expanding your data storytelling</title><link href="https://conor-hamill.github.io/blog/2024/visualisation-libraries-in-python-for-expanding-your-data-storytelling/" rel="alternate" type="text/html" title="Visualisation libraries in python for expanding your data storytelling"/><published>2024-03-30T11:41:15+00:00</published><updated>2024-03-30T11:41:15+00:00</updated><id>https://conor-hamill.github.io/blog/2024/visualisation-libraries-in-python-for-expanding-your-data-storytelling</id><content type="html" xml:base="https://conor-hamill.github.io/blog/2024/visualisation-libraries-in-python-for-expanding-your-data-storytelling/"><![CDATA[<h3>5 python packages for expanding your data storytelling</h3> <p>Data visualisation is a core part of how a data scientist tells a story, encompassing how they explore their data, share insights, and explain the impact of their models in their specific domain. The three most popular python libraries for visualisation are <a href="https://matplotlib.org/">matplotlib</a>, <a href="https://seaborn.pydata.org/">seaborn</a>, and <a href="https://plotly.com/">plotly</a>, with many other frameworks allowing the creation of impactful plots, like <a href="https://altair-viz.github.io/">Altair</a>, <a href="http://bokeh.org/">Bokeh</a>, and <a href="https://yhat.github.io/ggpy/">ggplot</a>.</p> <p>However, the core bread-and-butter python libraries that make up the skillsets of (many) modern data scientists are based around pandas, for data manipulation and analysis; scikit-learn, for pre-processing and modelling; and matplotlib for visualisation, respectively. Being able to expand upon these frameworks without having to learn a new framework and syntax allows a lot of impact with little effort and re-skilling.</p> <p>Inspired by this thought, this article explores five visualisation libraries that focus on expanding the capabilities of these core packages, including some thoughts on how well they deliver on their goals and which ones are worth adding to your arsenal. The five data visualisation libraries covered will be <a href="https://www.scikit-yb.org/en/latest/index.html">Yellowbrick</a>, <a href="https://rasbt.github.io/mlxtend/">Mlxtend</a>, <a href="https://github.com/matplotlib/mplfinance">mplfinance</a>, <a href="https://mpld3.github">mpld3</a>, and <a href="https://posit-dev.github.io/great-tables/articles/intro.html">great_tables</a>.</p> <h3>Yellowbrick</h3> <ul><li>Docs: <a href="https://www.scikit-yb.org/en/latest/index.html">https://www.scikit-yb.org/en/latest/index.html</a></li></ul> <p>The summary on its website gives a concise description of the package: <strong>“Yellowbrick extends the Scikit-Learn API to make model selection and hyperparameter tuning easier. Under the hood, it’s using Matplotlib”</strong>. It includes visualisations for many aspects of machine learning, including feature analysis, regression, classification, and clustering. Each of the visualisers on offer is implemented as a function and as a class, which simply wraps the function.</p> <p>To experiment with how flexible this would be with matplotlib subplots, I took the California Housing toy dataset from scikit-learn, for regression problems, and made a single figure with plots that show both the fit of the model and the distribution of the residuals of the fit. The visualisers can take scikit-learn pipelines as inputs, as well as classifiers, making reuse of scikit-learn code convenient.</p> <p>While I wasn’t able to get plotting on multiple matplotlib axes objects using the class-based API for visualisers, the “quick draw” functions shown below worked well, producing a plot that showed my regression fit, while also quickly showing that my residuals weren’t ideally distributed for a linear regression model. This implementation is shown in the code block below.</p> <pre>from sklearn.datasets import fetch_california_housing<br />import pandas as pd<br /><br />from sklearn.pipeline import make_pipeline<br />from sklearn.model_selection import train_test_split<br />from sklearn.preprocessing import StandardScaler<br />from sklearn.linear_model import LinearRegression<br />from sklearn.metrics import r2_score<br />import matplotlib.pyplot as plt<br /><br />from yellowbrick.regressor.prediction_error import prediction_error<br />from yellowbrick.regressor import residuals_plot<br /><br /># Getting example dataset<br />X, y = fetch_california_housing(return_X_y=True, as_frame=True)<br />X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)<br /><br />feature_cols = [<br />    &quot;MedInc&quot;,<br />    &quot;HouseAge&quot;,<br />    &quot;AveRooms&quot;,<br />    &quot;AveBedrms&quot;,<br />    &quot;Population&quot;,<br />    &quot;AveOccup&quot;,<br />]<br /><br />pipeline = make_pipeline(<br />    StandardScaler(),<br />    LinearRegression(),<br />)<br /><br />pipeline.fit(X_train[feature_cols], y_train)<br /><br />fig, axs = plt.subplots(2, 1, figsize=(14, 12));<br /><br /># quick draw method<br />visualiser_errors = prediction_error(<br />    pipeline,<br />    X_train[feature_cols],<br />    y_train,<br />    X_test[feature_cols],<br />    y_test,<br />    show=False,<br />    shared_limits=False,<br />    ax=axs[0],<br />)<br /><br /># quick draw method<br />visualiser_residuals = residuals_plot(<br />    pipeline,<br />    X_train[feature_cols],<br />    y_train,<br />    X_test[feature_cols],<br />    y_test,<br />    hist=False,<br />    qqplot=True,<br />    show=False,<br />    ax=axs[1],<br />)<br /><br />visualiser_errors.ax.set_xlim([0, 6])<br />visualiser_errors.ax.set_ylim([0, 8])<br />visualiser_errors.ax.legend(loc=2)<br /><br />fig</pre> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*bgjf5RZJTe83bmrycYNpQA.png"/><figcaption>Plot fit and residuals for linear regression model on the California Housing dataset, visualised using Yellowbrick.</figcaption></figure> <p>The plot above gives the insight I was looking for and only required two function calls to plot (plus some formatting).</p> <p><strong>My take: </strong>this package contains lots of functionality for informative visualisation, while allowing the reuse of scikit-learn pipelines and formatting using object-orientated matplotlib. I’d recommend this to any data scientist looking for a quick and easy way to visualise their models.</p> <h3>Mlxtend</h3> <ul><li>Docs: <a href="https://rasbt.github.io/mlxtend/">https://rasbt.github.io/mlxtend/</a></li></ul> <p>This package from the well-known data science researcher, author, and developer of <a href="https://lightning.ai/">PyTorch Lightning</a>, <a href="https://sebastianraschka.com/">Sebastian Raschka</a>, introduces itself as “<strong>Mlxtend (machine learning extensions) is a Python library of useful tools for the day-to-day data science tasks”. </strong>While not exclusively focussed on visualisation, it contains some visualisation options, with matplotlib as the backend.</p> <p>To give this package a spin, I decided to use the plot_decision_region() function, to compare the decision regions of the logistic regression, SVC, and adaboost classifiers on the penguins dataset. The code below shows the implementation of the plotting of three sub-plots, with an accuracy for each classifier as the title of the subplots.</p> <pre>from sklearn.linear_model import LogisticRegression<br />from sklearn.svm import SVC<br />from sklearn.ensemble import HistGradientBoostingClassifier, AdaBoostClassifier<br />from sklearn.impute import SimpleImputer<br />from sklearn.preprocessing import OneHotEncoder, LabelEncoder<br />from sklearn.compose import ColumnTransformer<br />from sklearn.metrics import accuracy_score<br />import numpy as np<br />from mlxtend.plotting import plot_decision_regions<br /><br /># penguins dataset downloaded locally<br />penguin_filepath = &quot;../data/penguins_size.csv&quot;<br />df_penguins = pd.read_csv(penguin_filepath)<br /><br />penguin_feature_cols = [<br />    &quot;culmen_length_mm&quot;,<br />    &quot;culmen_depth_mm&quot;,<br />    # &#39;flipper_length_mm&#39;, &#39;body_mass_g&#39;,<br />]<br /><br />le = LabelEncoder()<br /><br />X = df_penguins[penguin_feature_cols]<br />y = le.fit_transform(df_penguins[&quot;species&quot;])<br />X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)<br /><br />simple_inputer = SimpleImputer()<br />X_train = simple_inputer.fit_transform(X_train)<br />X_test = simple_inputer.transform(X_test)<br /><br />lr_model = LogisticRegression().fit(X_train, y_train)<br />svc_model = SVC().fit(X_train, y_train)<br />adab_model = AdaBoostClassifier().fit(X_train, y_train)<br /><br /># plotting<br />figure, ax = plt.subplots(1, 3, figsize=(16, 6))<br /><br />clf_names = [&quot;Logistic regression&quot;, &quot;SVC&quot;, &quot;AdaBoost&quot;]<br />clfs = [lr_model, svc_model, adab_model]<br /><br />xlabel, ylabel = penguin_feature_cols<br />for clf, clf_name, ax in zip(clfs, clf_names, axes):<br />    plot_decision_regions(X_test, y_test, clf=clf, ax=ax)<br /><br />    acc = accuracy_score(y_test, clf.predict(X_test))<br /><br />    ax.set_xlabel(xlabel)<br />    ax.set_ylabel(ylabel)<br />    ax.set_title(f&quot;{clf_name}: accuracy: {100.0 * acc:.2f}%&quot;)<br /><br />figure</pre> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*G3oAAciRBEtMQhgwADBEZA.png"/><figcaption>Decision regions for logistic regression, SVC, and adaboost classifiers on penguins dataset, visualised using the Mlxtend package.</figcaption></figure> <p>Relatively easily, we are able to plot the decision regions for each of these classifiers on the axes objects. These plots show how each of these classifiers separate predictions based on features, including exhibiting the overfitting of the adaboost classifier. We did have to convert the data to numpy arrays, as this function doesn’t accept pandas dataframes as input, despite pandas now accepting dataframes as input for transformers. Given how busy Sebastian Raschka has been with his other projects, I don’t think we can be too harsh about this.</p> <p><strong>My take: </strong>This package has plotting functionality that allows the user to get further insights into their models by re-using their scikit-learn models and enabling the use of matplotlib to configure the plots as you wish. The other functionality offered by the package is also definitely worth exploring.</p> <h3>mplfinance</h3> <ul><li>Docs: <a href="https://github.com/matplotlib/mplfinance">https://github.com/matplotlib/mplfinance</a></li></ul> <p>This package describes itself as <strong>“matplotlib utilities for the visualization, and visual analysis, of financial data”</strong>. The README in the GitHub repo describes the history of the package, which began as code extracted from the depreciated matplotlib.finance package, and had a previous form under the name mpl-finance. The package focuses on the visualisation of financial data (e.g. stock prices) over time and provides several examples of how to do this in its <a href="https://github.com/matplotlib/mplfinance/tree/master/examples">examples directory</a>.</p> <p>To give this package a try, I downloaded a sample of Apple’s stock price and plotted a candlestick plot for a sample of the stock price back in 2004.</p> <pre>import mplfinance as mpf<br />import matplotlib.pyplot as plt<br /><br />df_AAPL = pd.read_csv(&quot;../data/AAPL.csv.zip&quot;)<br /><br />df_AAPL.set_index(&quot;Date&quot;, inplace=True)<br />df_AAPL.index = pd.to_datetime(df_AAPL.index)<br />df_AAPL = df_AAPL[(df_AAPL.index &gt; &quot;2004-02-01&quot;) &amp; (df_AAPL.index &lt; &quot;2004-05-01&quot;)]<br /><br />mpf.plot(df_AAPL, type=&quot;candle&quot;, style=&quot;binance&quot;)</pre> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*93uq1AAk-EZSm3_fL4ZVcA.png"/><figcaption>Apple stock in early 2004, plotted using mplfinance.</figcaption></figure> <p>This shows a candlestick plot that looks decent, with one line of plotting. Provided the dataframe passed has the correct headings and the index set as the date, mplfinance can pick up the details it needs to create the plot.</p> <p>The package also has the option to add more information on the daily stock prices to the plots. Using the same data, I used the addplot option of mpl.plot to display the high and low values for each day in one subplot, above a subplot that showed the volume of stock traded every day and the range every day.</p> <pre>df_AAPL[&quot;range&quot;] = df_AAPL[&quot;High&quot;] - df_AAPL[&quot;Low&quot;]<br /><br />add_plots = [<br />    mpf.make_addplot(df_AAPL[[&quot;High&quot;, &quot;Low&quot;]]),<br />    mpf.make_addplot(df_AAPL[&quot;range&quot;], panel=1, color=&quot;g&quot;),<br />]<br />mpf.plot(df_AAPL, addplot=add_plots, volume=True)</pre> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*-MMwHE-NnJr7MRm-ODWe4w.png"/><figcaption>High and low values for Apple’s stock price in early 2004, above the volume traded and range for the stock, plotted using mpl.finance.</figcaption></figure> <p>This plot contains a lot of information, created with relatively few lines of code. However, the right-hand side y-axis on the lower plot is missing a label. Quite often, plotting functions like this will return the figure or axes objects automatically. However, in the doc string for the plot() function, there is no description of how to access this, or what the function can return. I dug into the source code and found that some of the kwargs provided to the function do have effects, including returnfig=True returning the figure and axes objects. From this, I was able to access the axis object I needed and add a label, but having to dig to find this functionality was fairly inconvenient.</p> <pre>fig, *axes_objects = mpf.plot(df_AAPL, addplot=add_plots, volume=True, returnfig=True)<br />axes_objects[0][3].set_ylabel(&quot;Range&quot;)<br /><br />fig</pre> <p><strong>My take: </strong>This package does enable visualisation of financial data in few lines of code. However, it is let down by the user having to really dig in to find the full functionality, and the slightly strange make_addplot API. That being said, this package has a lot of potential and the number of examples and plotting styles are good. A possible alternative for users would be the <a href="https://plotly.com/python/candlestick-charts/">implementation of candlestick charts in plotly</a>, which has the strong advantage of being able to zoom in on specific ranges in a long time series.</p> <h3>mpld3</h3> <ul><li>Docs: <a href="https://mpld3.github">https://mpld3.github</a></li></ul> <p>This package <strong>“brings together </strong><a href="http://www.matplotlib.org/"><strong>Matplotlib</strong></a><strong>…and </strong><a href="http://d3js.org/"><strong>D3js</strong></a><strong>, the popular JavaScript library for creating interactive data visualizations for the web”</strong>, setting out to tackle one of matplotlib’s biggest weaknesses - its lack of interactivity. The docs contain some nice examples of how this can be achieved in matplotlib plots, along with exporting the resulting plots as html.</p> <p>I used the penguins dataset again to give this library a try. One of the common problems when visualising large datasets is having overlapping distributions of several groups, making it difficult to observe and compare individual distributions. After trying to replicate the interactive legend example for histograms for each group, I had no success. After some searching, I concluded the containers that are used for histograms aren’t supported by mpld3, but I’d be delighted to be shown I’m wrong. Fortunately, I was able to get the scatter plot functionality working for the penguins dataset, giving me some information about the distribution of the two features, which would be very useful on a larger dataset.</p> <pre>fig, ax = plt.subplots(figsize=(10, 6))<br /><br />ax.grid(True, alpha=0.3)<br /><br />for species in df_penguins[&quot;species&quot;].unique():<br />    (l,) = ax.plot(<br />        df_penguins[df_penguins[&quot;species&quot;] == species][&quot;culmen_depth_mm&quot;].values,<br />        df_penguins[df_penguins[&quot;species&quot;] == species][&quot;culmen_length_mm&quot;].values,<br />        label=species,<br />        marker=&quot;.&quot;,<br />        markersize=20,<br />        linestyle=&quot;None&quot;,<br />    )<br /><br />handles, labels = ax.get_legend_handles_labels()  # return lines and labels<br />interactive_legend = plugins.InteractiveLegendPlugin(<br />    ax.lines, labels, alpha_unsel=0.1, alpha_over=1.5, start_visible=True<br />)<br /><br />plugins.connect(fig, interactive_legend)<br /><br />ax.set_xlabel(&quot;Culmen depth [mm]&quot;)<br />ax.set_ylabel(&quot;Culmen length [mm]&quot;)<br />ax.set_title(&quot;Culmen length vs depth&quot;, size=20)<br /><br />mpld3.display(fig)</pre> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*I6-7z_AaeW1R5y2qaNxuag.png"/></figure> <p>The above picture obviously doesn’t display the functionality, but by clicking on the legend in the notebook the individual groups will disappear, and this can also be exported to a html file. Also, before the plugins from mpld3 get used, no changes to the code are needed, meaning existing matplotlib code can be easily extended to give this functionality.</p> <p><strong>My take: </strong>This package makes a solid attempt towards adding interactivity to matplotlib, and has an appealing syntax in that existing matplotlib scripts can have a few lines of code appended to give interactivity. However, it doesn’t work for all types of matplotlib plots, and <a href="https://mpld3.github.io/faq.html#general">judging by the FAQ</a>, adding interactivity simply won’t be possible for some types of plots, meaning following a plotly example might be your best bet if you’re starting from scratch and want interactivity.</p> <h3>great_tables</h3> <ul><li>Docs: <a href="https://posit-dev.github.io/great-tables/articles/intro.html">https://posit-dev.github.io/great-tables/articles/intro.html</a></li></ul> <p>While displaying data in tabular format might not be the first thing people think of when they hear data visualisation, a well-structure table of aggregated data in a table can be an effective way of displaying information for a report or presentation, and being able to generate these tables automatically makes life much easier. This package introduces itself as <strong>“a Python package for creating great-looking display tables”</strong>, and makes the distinction that this is aimed to offer features to create tables “you’d find in a web page, a journal article, or magazine”.</p> <p>To give this package a go and see how pretty a table I could create, I downloaded a table of New York property prices from Kaggle and set about displaying some aggregate properties for each area, included in the code snippet below.</p> <pre>from great_tables import GT<br />from great_tables import html, md<br /><br />import calendar<br /><br />df_NY = pd.read_csv(NY_housing_path)<br /><br />NO_BEDS_COL = &quot;No. beds&quot;<br />NO_BATHS_COL = &quot;No. baths&quot;<br />FLOOR_AREA_COL = &quot;Floor area [sqft]&quot;<br />NO_LISTINGS_COL = &quot;No. listings&quot;<br />PRICE_COL = &quot;Price&quot;<br />LOCALITY_COL = &quot;NY Locality&quot;<br /><br />rename_dict = {<br />    &quot;LOCALITY&quot;: LOCALITY_COL,<br />    &quot;BEDS&quot;: NO_BEDS_COL,<br />    &quot;BATH&quot;: NO_BATHS_COL,<br />    &quot;PROPERTYSQFT&quot;: FLOOR_AREA_COL,<br />    &quot;ADDRESS&quot;: NO_LISTINGS_COL,<br />    &quot;PRICE&quot;: PRICE_COL,<br />}<br /><br />GT( # pandas dataframe serves as inupt to GT onject<br />    pd.concat( # aggregating data using pandas<br />        [<br />            df_NY.groupby(by=[&quot;LOCALITY&quot;])[<br />                [&quot;BEDS&quot;, &quot;BATH&quot;, &quot;PROPERTYSQFT&quot;, &quot;PRICE&quot;]<br />            ].median(),<br />            df_NY.groupby(by=[&quot;LOCALITY&quot;])[[&quot;ADDRESS&quot;]].count(),<br />        ],<br />        axis=1,<br />    )<br />    .reset_index()<br />    .rename(columns=rename_dict)<br />).fmt_integer( # table display from chained methods<br />    columns=[NO_BEDS_COL, NO_BATHS_COL, FLOOR_AREA_COL, NO_LISTINGS_COL]<br />).fmt_currency(<br />    columns=PRICE_COL<br />).tab_spanner(<br />    label=md(&quot;*Median property properties*&quot;),<br />    columns=[NO_BEDS_COL, NO_BATHS_COL, FLOOR_AREA_COL, PRICE_COL],<br />).tab_source_note(<br />    source_note=f&quot;Source: {source_address}&quot;<br />).tab_header(<br />    title=html(&quot;&lt;strong&gt;Properties across New York&lt;/strong&gt;&quot;),<br />    subtitle=html(&quot;Average property properties by New York localities&quot;),<br />)</pre> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*vAMobWeqWbdzh2IspHuaKQ.png"/></figure> <p>As the code snippet shows, the ability to chain methods together allows fine control of the components of the table, including formatting and naming the source.</p> <p>A similar exercise below on sales from a Walmart dataset allowed the sales across different stores to be summarised easily.</p> <pre>df_sales = pd.read_csv(WALMART_SALES_FILE)<br />df_sales[&quot;Date&quot;] = pd.to_datetime(df_sales[&quot;Date&quot;], format=&quot;%d-%m-%Y&quot;)<br /><br /># Only selecting some stores as a sample<br />df_sales = df_sales.loc[df_sales[&quot;Store&quot;] &lt; 6, :]<br /><br />df_sales.loc[:, &quot;Month&quot;] = df_sales[&quot;Date&quot;].dt.month<br /><br /># calculating percentage of sales per month<br />groupby = df_sales.groupby(by=[&quot;Month&quot;, &quot;Store&quot;])[&quot;Weekly_Sales&quot;].mean().unstack()<br />groupby_percentage_sales_per_month = groupby / groupby.sum(axis=0)<br />groupby_percentage_sales_per_month.reset_index(inplace=True)<br /><br />groupby_percentage_sales_per_month[&quot;Month&quot;] = groupby_percentage_sales_per_month[<br />    &quot;Month&quot;<br />].apply(lambda x: calendar.month_abbr[x])<br /><br />groupby_percentage_sales_per_month.columns = (<br />    groupby_percentage_sales_per_month.columns.astype(&quot;str&quot;)<br />)<br /><br />GT(<br />    groupby_percentage_sales_per_month,<br />    rowname_col=&quot;Month&quot;,<br />).data_color(<br />    # domain=[0.8, 0.10],<br />    palette=[&quot;rebeccapurple&quot;, &quot;white&quot;, &quot;orange&quot;],<br />    na_color=&quot;white&quot;,<br />).tab_header(<br />    title=&quot;Average percentage yearly sales by month for five Walmart stores&quot;,<br />    # subtitle=html(&quot;Average monthly values at latitude of 20&amp;deg;N.&quot;),<br />).tab_source_note(<br />    source_note=f&quot;Source: https://www.kaggle.com/datasets/mikhail1681/walmart-sales&quot;<br />).fmt_percent(<br />    [<br />        &quot;1&quot;,<br />        &quot;2&quot;,<br />        &quot;3&quot;,<br />        &quot;4&quot;,<br />        &quot;5&quot;,<br />    ],<br />    decimals=2,<br />)</pre> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*yRQ9M4wcVhIdKQIFqCCPNw.png"/></figure> <p>Again, with a few chained methods, we have a table that allows us to clearly see some trends across these five different shops. You can quickly see how (unsurprisingly) sales peak in December, with lower fractions of sales in January and July.</p> <p><strong>My take: </strong>This is a well-developed package that makes creating tables for presentation straightforward. Taking pandas dataframes as inputs to the GT class, along with the option of chaining of formatting methods, makes this a straightforward package to adapt. As a researcher, if this could export to LaTeX format, that would be amazing. Thankfully <a href="https://github.com/posit-dev/great-tables/issues/75">someone has already submitted an issue asking for this as a feature</a>, with an estimation of “done in early-to-mid 2024”, so this feature is eagerly awaited</p> <h3>Conclusion</h3> <p>Hopefully you found this article somewhat interesting and useful. I believe the breadth of the packages here strongly underline the strengths of the scientific python stack. The notebook the plots and tables in this article were created in can be found on my GitHub <a href="https://github.com/conorhamill36/viz_packages">here</a>. Please share any constructive criticism, including anything key in the packages I missed, and any other visualisation packages that expand upon pandas/scikit-learn/matplotlib well!</p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=e0dc4ca54302" width="1" height="1" alt=""/>&lt;hr&gt;&lt;p&gt;<a href="https://medium.com/swlh/visualisation-libraries-in-python-for-expanding-your-data-storytelling-e0dc4ca54302">Visualisation libraries in python for expanding your data storytelling</a> was originally published in <a href="https://medium.com/swlh">The Startup</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</p>]]></content><author><name></name></author></entry></feed>