<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <p><em>By </em><a href="https://www.linkedin.com/in/conor-hamill/" rel="external nofollow noopener" target="_blank"><em>Conor Hamill (Senior Data Scientist, AI R&amp;D)</em></a></p> <p>In the fast-evolving world of technology and financial services, one thing is clear: the pace of advancement in AI has been nothing short of astonishing. With the annual publication of AI research papers soaring, we are witnessing capabilities that seemed far-fetched just a few years ago now being integrated into everyday workflows for individuals and businesses alike. The ideas and innovations in cutting-edge techniques in machine learning and AI from academia and industry are vividly showcased at international conferences like NeurIPS, often hailed as one of the largest and most influential gatherings in the realm of machine learning and AI.</p> <p>It was great to see NatWest Group as a bronze sponsor of NeurIPS 2024, with Conor Hamil and Raad Khraishi representing the bank during the week-long conference in December.</p> <h3>Exploring a wealth of research at NeurIPS</h3> <p>NeurIPS 2024 was held in the Vancouver Conference Centre, with the city nestled between the mountains and the sea serving as an inspiring environment for the conference.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/432/0*OzPTm9W3rGaNDiF7.jpeg"><figcaption>The Vancouver Conference Centre.</figcaption></figure> <figure><img alt="" src="https://cdn-images-1.medium.com/max/426/0*fMbf0cihNfRgk70w.jpeg"><figcaption>The welcome talk for NeurIPS 2024.</figcaption></figure> <p>Unsurprisingly, large language models (LLMs) were a major focal point of this year’s conference, with many ground-breaking studies addressing key challenges and advancements in this area. Researchers explored mitigating hallucinations in outputs (<a href="https://openreview.net/forum?id=1Fc2Xa2cDK&amp;referrer=%5Bthe%20profile%20of%20Fred%20A.%20Hamprecht%5D(%2Fprofile%3Fid%3D~Fred_A._Hamprecht1)" rel="external nofollow noopener" target="_blank">Truth is Universal: Robust Detection of Lies in LLMs</a>), in-depth studies predicting the emergence of abilities during pre-training (<a href="https://openreview.net/forum?id=On5WIN7xyD" rel="external nofollow noopener" target="_blank">Observational Scaling Laws and the Predictability of Language Model Performance</a>), and optimising prompts for tasks (<a href="https://openreview.net/forum?id=FLNnlfBGMo" rel="external nofollow noopener" target="_blank">Efficient Prompt Optimization Through the Lens of Best Arm Identification</a>).</p> <p>Simultaneously, there was a huge focus on maintaining the same performance of LLMs while reducing the amount of compute (<a href="https://openreview.net/forum?id=manHbkpIW6" rel="external nofollow noopener" target="_blank">Once Read is Enough</a>), training data (<a href="https://openreview.net/forum?id=0NMzBwqaAJ" rel="external nofollow noopener" target="_blank">Not All Tokens Are What You Need for Pretraining</a>), and model parameters (<a href="https://proceedings.neurips.cc/paper_files/paper/2024/hash/ab6eba9a853087993addff937c8cec87-Abstract-Conference.html" rel="external nofollow noopener" target="_blank">Towards Next-Level Post-Training Quantization of Hyper-Scale Transformers</a>) required. Progress in these endeavours is essential for developing faster, more cost-effective models and enhancing computing capabilities on edge devices.</p> <p>The development of LLM agents using these LLMs made up a large amount of the work in the conference. This included works exploring different workflows of LLM agents (<a href="https://proceedings.neurips.cc/paper_files/paper/2024/hash/ee71a4b14ec26710b39ee6be113d7750-Abstract-Conference.html" rel="external nofollow noopener" target="_blank">Chain of Agents: Large Language Models Collaborating on Long-Context Tasks</a>) and enhanced agent capabilities (<a href="https://openreview.net/forum?id=3l2HnZXNou" rel="external nofollow noopener" target="_blank">Multi-Agent Coordination via Multi-Level Communication</a>), as well as the emerging capabilities of multi-model agents (<a href="https://proceedings.neurips.cc/paper_files/paper/2024/hash/f7ae4fe91d96f50abc2211f09b6a7e49-Abstract-Conference.html" rel="external nofollow noopener" target="_blank">FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement</a>).</p> <p>As LLMs get deployed in more and more applications, some of which are critical or contain sensitive information for end users, the understanding of the potential risks to these systems and how these can be mitigated is crucial, and research into these threats was very prominent at the NeurIPS conference. Works looking at jail-breaking of LLMs (<a href="https://proceedings.neurips.cc/paper_files/paper/2024/hash/439bf902de1807088d8b731ca20b0777-Abstract-Conference.html" rel="external nofollow noopener" target="_blank">Mission Impossible: A Statistical Perspective on Jailbreaking LLMs</a>), toxicity detection (<a href="https://openreview.net/forum?id=5a27EE8LxX" rel="external nofollow noopener" target="_blank">Toxicity Detection for Free</a>) and the emerging risks from agents (<a href="https://proceedings.neurips.cc/paper_files/paper/2024/hash/b6e9d6f4f3428cd5f3f9e9bbae2cab10-Abstract-Conference.html" rel="external nofollow noopener" target="_blank">Watch Out for Your Agents!</a>).</p> <p>Additionally, many discussions focused on the pressing challenges of fairness and bias in AI, as well as innovative efforts to address them. This included processes for de-biasing datasets (<a href="https://openreview.net/forum?id=ZVrrPNqHFw" rel="external nofollow noopener" target="_blank">A Simple Remedy for Dataset Bias via Self-Influence</a>), methods for estimating the fairness of algorithms (<a href="https://openreview.net/forum?id=ztwl4ubnXV&amp;referrer=%5Bthe%20profile%20of%20Zihao%20Fu%5D(%2Fprofile%3Fid%3D~Zihao_Fu1)" rel="external nofollow noopener" target="_blank">OxonFair: A Flexible Toolkit for Algorithmic Fairness</a>), and improvements on performance on under-represented groups in datasets (<a href="https://openreview.net/forum?id=vJLTcCBZVT" rel="external nofollow noopener" target="_blank">Improving Subgroup Robustness via Data Selection</a>).</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/635/0*viqopFaQeN2n5jRt.jpeg"><figcaption>Poster sessions enabled researchers to share ideas and insights.</figcaption></figure> <p>All of these discussions were vital for us as scientists and engineers to ensure we keep these challenges at the front of our minds when using technology to develop services aimed at improving how we serve our customers.</p> <h3>The thriving AI community at NeurIPS</h3> <p>NeurIPS wasn’t just significant in terms of attendance; it also featured an impressive variety of events throughout the week and beyond. Participants could choose from engaging workshops and tutorials, as well as innovative projects presented by high school students. As well as this, there were affinity events and creative AI sessions throughout, and a huge number of community groups organised, meaning, despite the thousands of people there, there was an opportunity for everyone to connect with others who shared similar interests, making the experience inclusive and enriching despite the large turnout.</p> <p>The Exhibits Hall was alive with excitement, buzzing as vendors showcased their ground-breaking innovations and shared invaluable insights with conference presenters and attendees. Renowned tech giants like Google and Amazon drew large crowds, while dynamic startups such as Wayve exhibited their fresh ideas.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/619/0*iBw3B8Kvw7v4nuwG.jpeg"><figcaption>Large tech companies and startups alike filled the Exhibition Hall.</figcaption></figure> <h3>Looking back and looking forward in AI</h3> <p>The past decade has been an incredible time for the field of machine learning and AI and the next ten years promises to be just as exciting. NeurIPS has a longstanding tradition of recognizing research that significantly impacts the field through its “Test of Time” award. This prestigious accolade honours the authors of seminal papers presented at the conference a decade ago. At the 2024 conference, two noteworthy works received this prize: the influential paper on <strong>“Generative Adversarial Networks”</strong> (GANs), which introduced a revolutionary framework for generative models, and <strong>“Sequence to Sequence Learning with Neural Networks”,</strong> which laid the groundwork for the advanced architectures that power today’s notable language models.</p> <p>A reflection of the former paper was presented by Ian Goodfellow and David Warde-Farley, while Ilya Sutskever, still one of the most well-known individuals in AI, presented reflections on the latter work and what he thought the future held for the field.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/608/0*pZ12u-BOi8c0N96s.jpeg"><figcaption>Ilya Sutskever’s Test of Time talk reflected on the successes of the past decade and speculated where the field is going next.</figcaption></figure> <p>In his engaging talk, Sutskever highlighted that we are transitioning away from an era where advancements in models solely relied on scaling training compute and data. He pointed out the field is changing rapidly, with the focus shifting to agents, synthetic data, and test-time compute. This has been borne out in recent months, with the recent surge in research on agents and the release of reasoning models like OpenAI’s o3 model.</p> <h3>Arriving home full of ideas</h3> <p>Attending this event and seeing the cutting-edge of AI research, along with the individuals that have driven the field towards such success, was an amazing experience. Seeing NatWest Group sponsoring an event like this, alongside names like Duolingo, showed me how committed the bank is to being at the forefront of research.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/560/0*5tfxwPt8B_ituxM6.jpeg"><figcaption>Conor Hamill and Raad Khraishi represented NatWest at the conference.</figcaption></figure> <p>We arrived home with loads of research ideas in our minds, eager to explore how the innovations we had seen could steer and be built on by <a href="https://www.natwestgroup.com/news-and-insights/latest-stories/ai-and-data/2024/aug/ai-research.html" rel="external nofollow noopener" target="_blank">the AI research happening across the bank</a> and with our university collaborators. Being able to see so much in such a short space of time kept us at the forefront of AI transformation and the support of senior data leaders in the bank meant that we were able to do this. AI is helping to accelerate change in financial services, and attending events like NeurIPS informs our research and equips us to deliver for our customers and stay on top of the cutting-edge developments that are shaping the future of banking.</p> <p>If you found this blog post interesting and would like to work on similar problems, we encourage you to take a look at our <a href="https://jobs.natwestgroup.com/pages/technology-digital-data?utm_source=natwestgroup.com&amp;utm_medium=referral&amp;utm_campaign=march_nwg_engineering_blog" rel="external nofollow noopener" target="_blank">available job openings</a>!</p> <p><em>The views and opinions expressed in this article are those of the author and do not necessarily represent the views of the NatWest Group.</em></p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=ab872d34ed01" width="1" height="1" alt="">&lt;hr&gt;&lt;p&gt;<a href="https://nwg.ai/natwest-group-ai-team-at-neurips-2024-ab872d34ed01" rel="external nofollow noopener" target="_blank">NatWest Group AI team at NeurIPS 2024</a> was originally published in <a href="https://nwg.ai" rel="external nofollow noopener" target="_blank">NatWest Group AI &amp; Engineering</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;</p> </body></html>